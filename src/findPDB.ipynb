{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_k_zEzVEhiwv",
    "outputId": "4550d88b-4d2f-4655-a0b3-fabe599861a4"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Results saved to sequence_pdb_matches.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "INPUT_FILE = \"https://raw.githubusercontent.com/Jeffateth/AllergenPredict/main/allergen_data_with_full_sequences.csv\"  # change input file\n",
    "SEQUENCE_COLUMN = (\n",
    "    \"full_parent_protein_sequence\"  # specify in which column the sequence is saved\n",
    ")\n",
    "\n",
    "\n",
    "def search_rcsb_by_sequence(sequence):\n",
    "    \"\"\"Search the RCSB PDB by an amino acid sequence using a POST request.\"\"\"\n",
    "    url = \"https://search.rcsb.org/rcsbsearch/v2/query\"\n",
    "\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"type\": \"terminal\",\n",
    "            \"service\": \"sequence\",\n",
    "            \"parameters\": {\n",
    "                \"evalue_cutoff\": 0.1,\n",
    "                \"identity_cutoff\": 0.9,\n",
    "                \"target\": \"pdb_protein_sequence\",\n",
    "                \"value\": sequence,\n",
    "            },\n",
    "        },\n",
    "        \"return_type\": \"entry\",\n",
    "    }\n",
    "\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    response = requests.post(url, json=query, headers=headers)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        pdb_ids = [result[\"identifier\"] for result in data.get(\"result_set\", [])]\n",
    "        return pdb_ids\n",
    "    elif response.status_code == 204:\n",
    "        return []  # No content (no matches found)\n",
    "    else:\n",
    "        print(f\"Error {response.status_code} for sequence: {sequence}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Read the input CSV\n",
    "    df = pd.read_csv(INPUT_FILE)\n",
    "\n",
    "    # Check if the expected column exists\n",
    "    if SEQUENCE_COLUMN not in df.columns:\n",
    "        print(f\"Column '{SEQUENCE_COLUMN}' not found in the input file.\")\n",
    "        return\n",
    "\n",
    "    # Work with the first 1000 sequences and filter out short ones\n",
    "    # df_subset = df.head(1000).copy()\n",
    "    df_subset = df[df[SEQUENCE_COLUMN].str.len() >= 20]\n",
    "\n",
    "    # Create a new column to hold matching PDB codes\n",
    "    df_subset[\"pdb_matches\"] = df_subset[SEQUENCE_COLUMN].apply(\n",
    "        lambda seq: search_rcsb_by_sequence(seq)\n",
    "    )\n",
    "\n",
    "    # Save results\n",
    "    df_subset.to_csv(\"sequence_pdb_matches.csv\", index=False)\n",
    "    print(\"Results saved to sequence_pdb_matches.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "df_matches = pd.read_csv(\"sequence_pdb_matches.csv\")\n",
    "print(df_matches)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dz_DDj3_o4LG",
    "outputId": "2f748c3b-8d80-436a-f00f-548d30ffa5e9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    epitope_sequence  \\\n",
      "0    FGGRAEWGTNTADNDDTDGNGHGTHTASTAA   \n",
      "1               TEEEKNRLNFLKKISQRYQK   \n",
      "2      TAIFQDTVRAEMTKVLAPAFKKELERNNQ   \n",
      "3               RQRVEQEQEQEQDEYPYSQR   \n",
      "4           PKHADADNILVIQQGQATVTVANG   \n",
      "..                               ...   \n",
      "155             TALKKAITAMSQAQKAAKPA   \n",
      "156             ELFRQFYQLDAYPSGAWYYV   \n",
      "157             KAKFETFKKEMKAKEAELAK   \n",
      "158         ARQQWELQEDRRCQSQLERANLRP   \n",
      "159             PYSPSQDPDRRDPYSPSPYD   \n",
      "\n",
      "                                   protein_url  label  \\\n",
      "0        http://www.uniprot.org/uniprot/P9WEW4      0   \n",
      "1        http://www.uniprot.org/uniprot/P02663      0   \n",
      "2        http://www.uniprot.org/uniprot/P49273      1   \n",
      "3        http://www.uniprot.org/uniprot/Q9SQH1      1   \n",
      "4        http://www.uniprot.org/uniprot/B3IXL2      1   \n",
      "..                                         ...    ...   \n",
      "155      http://www.uniprot.org/uniprot/P22286      0   \n",
      "156      http://www.uniprot.org/uniprot/P02662      1   \n",
      "157  http://www.uniprot.org/uniprot/A0A3P6NWQ2      0   \n",
      "158      http://www.uniprot.org/uniprot/Q6PSU2      1   \n",
      "159      http://www.uniprot.org/uniprot/Q6PSU2      1   \n",
      "\n",
      "                          full_parent_protein_sequence  \\\n",
      "0    MGFLKLLSTSLATLAVVNAGKLLTANDGDEVVPSSYIVVMNDGVST...   \n",
      "1    MKFFIFTCLLAVALAKNTMEHVSSSEESIISQETYKQEKNMAINPS...   \n",
      "2    MMKLLLIAAAAFVAVSADPIHYDKITEEINKAVDEAVAAIEKSETF...   \n",
      "3    MMVKLSILVALLGALLVVASATRWDPDRGSRGSRWDAPSRGDDQCQ...   \n",
      "4    MRGRVSPLMLLLGILVLASVSATQAKSPYRKTENPCAQRCLQSCQQ...   \n",
      "..                                                 ...   \n",
      "155  MAVQKYTVALFLVALVVGPAASYAADLSYGAPATPAAPAAGYTPAA...   \n",
      "156  MKLLILTCLVAVALARPKHPIKHQGLPQEVLNENLLRFFVAPFPEV...   \n",
      "157  MVVLKASRLPKTMKTLIVAALFCTIGMALADDTPPPPPFLAGAPQD...   \n",
      "158  MAKLTILVALALFLLAAHASARQQWELQGDRRCQSQLERANLRPCE...   \n",
      "159  MAKLTILVALALFLLAAHASARQQWELQGDRRCQSQLERANLRPCE...   \n",
      "\n",
      "                  pdb_matches  \n",
      "0                    ['5Z6O']  \n",
      "1            ['6FS4', '6FS5']  \n",
      "2                    ['3H4Z']  \n",
      "3                          []  \n",
      "4    ['3S7E', '3S7I', '3SMH']  \n",
      "..                        ...  \n",
      "155                        []  \n",
      "156                        []  \n",
      "157                  ['2MAR']  \n",
      "158                  ['8SJ6']  \n",
      "159                        []  \n",
      "\n",
      "[160 rows x 5 columns]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!ls"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zwt32N8scgyG",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745324483124,
     "user_tz": -300,
     "elapsed": 135,
     "user": {
      "displayName": "Alexey Ganzha",
      "userId": "18251908108815644034"
     }
    },
    "outputId": "6afbc011-0497-4d77-cf0f-4b047e2bbc68"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "sample_data\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Comprehensive per‑residue structural descriptor calculation from a PDB,\n",
    "with automatic installation of missing dependencies, and Biopython ≥ 1.80 support.\n",
    "\n",
    "Usage:\n",
    "    python analyze_protein.py <path/to/structure.pdb>\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 1) Auto‑install missing packages\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "\n",
    "for pkg in (\"numpy\", \"pandas\", \"mdtraj\", \"biopython\"):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        print(f\"Package '{pkg}' not found. Installing...\")\n",
    "        install(pkg)\n",
    "\n",
    "# Now safe to import everything\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.PDB import PDBParser, HSExposureCA\n",
    "from Bio.Data.PDBData import protein_letters_3to1\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 2) Constants\n",
    "# --------------------------------------------------\n",
    "MAX_ASA = {\n",
    "    \"A\": 121,\n",
    "    \"R\": 265,\n",
    "    \"N\": 187,\n",
    "    \"D\": 187,\n",
    "    \"C\": 148,\n",
    "    \"Q\": 214,\n",
    "    \"E\": 223,\n",
    "    \"G\": 97,\n",
    "    \"H\": 216,\n",
    "    \"I\": 195,\n",
    "    \"L\": 191,\n",
    "    \"K\": 230,\n",
    "    \"M\": 203,\n",
    "    \"F\": 228,\n",
    "    \"P\": 154,\n",
    "    \"S\": 143,\n",
    "    \"T\": 163,\n",
    "    \"W\": 264,\n",
    "    \"Y\": 255,\n",
    "    \"V\": 165,\n",
    "}\n",
    "\n",
    "HYDRO = {\n",
    "    \"A\": 1.8,\n",
    "    \"R\": -4.5,\n",
    "    \"N\": -3.5,\n",
    "    \"D\": -3.5,\n",
    "    \"C\": 2.5,\n",
    "    \"Q\": -3.5,\n",
    "    \"E\": -3.5,\n",
    "    \"G\": -0.4,\n",
    "    \"H\": -3.2,\n",
    "    \"I\": 4.5,\n",
    "    \"L\": 3.8,\n",
    "    \"K\": -3.9,\n",
    "    \"M\": 1.9,\n",
    "    \"F\": 2.8,\n",
    "    \"P\": -1.6,\n",
    "    \"S\": -0.8,\n",
    "    \"T\": -0.7,\n",
    "    \"W\": -0.9,\n",
    "    \"Y\": -1.3,\n",
    "    \"V\": 4.2,\n",
    "}\n",
    "\n",
    "VDW_RADII = {\"H\": 1.2, \"C\": 1.7, \"N\": 1.55, \"O\": 1.52, \"S\": 1.8}\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 3) Helper to map 3‑letter → 1‑letter\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def resname_to_one(resname):\n",
    "    \"\"\"Convert a three‑letter residue name to one‑letter code, default 'X'.\"\"\"\n",
    "    return protein_letters_3to1.get(resname.upper(), \"X\")\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 4) Core functions\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def load_structures(pdb_path):\n",
    "    traj = md.load(pdb_path)\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure(\"X\", pdb_path)\n",
    "    return traj, structure\n",
    "\n",
    "\n",
    "def compute_sasa(traj, structure):\n",
    "    sasa_nm2 = md.shrake_rupley(traj, probe_radius=0.14, mode=\"residue\")\n",
    "    sasa = sasa_nm2[0] * 100.0  # nm² → Å²\n",
    "    norm = []\n",
    "    for res in structure.get_residues():\n",
    "        aa1 = resname_to_one(res.get_resname())\n",
    "        max_ = MAX_ASA.get(aa1, np.nan)\n",
    "        norm.append(sasa[res.id[1] - 1] / max_ if max_ else np.nan)\n",
    "    return sasa, np.array(norm)\n",
    "\n",
    "\n",
    "def compute_torsions(traj, structure):\n",
    "    phi_idx, phi_vals = md.compute_phi(traj)\n",
    "    psi_idx, psi_vals = md.compute_psi(traj)\n",
    "    om_idx, om_vals = md.compute_omega(traj)\n",
    "    chi1_idx, chi1_vals = md.compute_chi1(traj)\n",
    "\n",
    "    phi = dict(zip(phi_idx[:, 1], phi_vals[0]))\n",
    "    psi = dict(zip(psi_idx[:, 1], psi_vals[0]))\n",
    "    omega = dict(zip(om_idx[:, 1], om_vals[0]))\n",
    "    chi1 = dict(zip(chi1_idx[:, 0], chi1_vals[0]))\n",
    "\n",
    "    phis = []\n",
    "    psis = []\n",
    "    omegas = []\n",
    "    chis = []\n",
    "    for res in structure.get_residues():\n",
    "        i = res.id[1] - 1\n",
    "        phis.append(phi.get(i, np.nan))\n",
    "        psis.append(psi.get(i, np.nan))\n",
    "        omegas.append(omega.get(i, np.nan))\n",
    "        chis.append(chi1.get(i, np.nan))\n",
    "    return (np.array(phis), np.array(psis), np.array(omegas), np.array(chis))\n",
    "\n",
    "\n",
    "def compute_hbonds(traj, structure):\n",
    "    hbonds = md.baker_hubbard(traj, periodic=False)[0]\n",
    "    counts = {r.id[1]: 0 for r in structure.get_residues()}\n",
    "    for d, a, *_ in hbonds:\n",
    "        counts[traj.topology.atom(d).residue.id] += 1\n",
    "        counts[traj.topology.atom(a).residue.id] += 1\n",
    "    return np.array([counts[r.id[1]] for r in structure.get_residues()])\n",
    "\n",
    "\n",
    "def compute_salt_bridges(traj, structure, cutoff=0.4):\n",
    "    neg = traj.topology.select(\"resname ASP GLU and name OD1 OD2 OE1 OE2\")\n",
    "    pos = traj.topology.select(\"resname LYS ARG HIS and name NZ NH1 NH2 NE\")\n",
    "    d = md.compute_distances(traj, np.array([[i, j] for i in neg for j in pos]))[0]\n",
    "    pairs = np.where(d < cutoff)\n",
    "    counts = {r.id[1]: 0 for r in structure.get_residues()}\n",
    "    for ni, pi in zip(*pairs):\n",
    "        ri = traj.topology.atom(neg[ni]).residue.id\n",
    "        rj = traj.topology.atom(pos[pi]).residue.id\n",
    "        counts[ri] += 1\n",
    "        counts[rj] += 1\n",
    "    return np.array([counts[r.id[1]] for r in structure.get_residues()])\n",
    "\n",
    "\n",
    "def compute_ss_bridges(traj, structure, cutoff=0.22):\n",
    "    sg = traj.topology.select(\"resname CYS and name SG\")\n",
    "    d = md.compute_distances(traj, np.array([[i, j] for i in sg for j in sg]))[0]\n",
    "    pairs = np.where((d < cutoff) & (d > 0))\n",
    "    bonded = set()\n",
    "    for i, j in zip(*pairs):\n",
    "        bonded.update(\n",
    "            [traj.topology.atom(sg[i]).residue.id, traj.topology.atom(sg[j]).residue.id]\n",
    "        )\n",
    "    return np.array([1 if r.id[1] in bonded else 0 for r in structure.get_residues()])\n",
    "\n",
    "\n",
    "def compute_pi_pi(traj, structure, cutoff=0.7):\n",
    "    arom = {\n",
    "        \"PHE\": (\"CG\", \"CD1\", \"CD2\", \"CE1\", \"CE2\", \"CZ\"),\n",
    "        \"TYR\": (\"CG\", \"CD1\", \"CD2\", \"CE1\", \"CE2\", \"CZ\"),\n",
    "        \"TRP\": (\"CG\", \"CD1\", \"CD2\", \"NE1\", \"CE2\", \"CE3\", \"CZ2\", \"CZ3\", \"CH2\"),\n",
    "    }\n",
    "    cents = {}\n",
    "    for chain in structure:\n",
    "        for res in chain:\n",
    "            name = res.get_resname()\n",
    "            if name in arom:\n",
    "                coords = np.array(\n",
    "                    [a.get_vector() for a in res if a.get_name() in arom[name]]\n",
    "                )\n",
    "                cents[res.id[1]] = coords.mean(axis=0)\n",
    "    counts = {r.id[1]: 0 for r in structure.get_residues()}\n",
    "    keys = list(cents)\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(i + 1, len(keys)):\n",
    "            if np.linalg.norm(cents[keys[i]] - cents[keys[j]]) < cutoff * 10:\n",
    "                counts[keys[i]] += 1\n",
    "                counts[keys[j]] += 1\n",
    "    return np.array([counts[r.id[1]] for r in structure.get_residues()])\n",
    "\n",
    "\n",
    "def compute_vdw_contacts(traj, structure, extra=0.05):\n",
    "    coords = traj.xyz[0] * 10\n",
    "    elems = [a.element.symbol for a in traj.topology.atoms]\n",
    "    radii = np.array([VDW_RADII.get(e, 1.5) for e in elems])\n",
    "    pairs = np.array(\n",
    "        [[i, j] for i in range(len(coords)) for j in range(i + 1, len(coords))]\n",
    "    )\n",
    "    dists = np.linalg.norm(coords[pairs[:, 0]] - coords[pairs[:, 1]], axis=1)\n",
    "    thresh = radii[pairs[:, 0]] + radii[pairs[:, 1]] + extra\n",
    "    hits = pairs[dists < thresh]\n",
    "    resmap = {a.index: a.residue.id[1] for a in traj.topology.atoms}\n",
    "    conts = {r.id[1]: set() for r in structure.get_residues()}\n",
    "    for i, j in hits:\n",
    "        ri, rj = resmap[i], resmap[j]\n",
    "        if ri != rj:\n",
    "            conts[ri].add(rj)\n",
    "            conts[rj].add(ri)\n",
    "    return np.array([len(conts[r.id[1]]) for r in structure.get_residues()])\n",
    "\n",
    "\n",
    "def compute_packing_density(traj, structure, r=1.0):\n",
    "    ca = traj.topology.select(\"name CA\")\n",
    "    coords = traj.xyz[0]\n",
    "    vol = 4 / 3 * np.pi * r**3 * 1e3\n",
    "    pd = []\n",
    "    for idx, res in enumerate(structure.get_residues()):\n",
    "        d = np.linalg.norm((coords - coords[0][ca[idx]]), axis=2) * 10\n",
    "        pd.append((np.sum(d < r * 10) - 1) / vol)\n",
    "    return np.array(pd)\n",
    "\n",
    "\n",
    "def compute_depth_protrusion(structure):\n",
    "    atoms = np.array([a.get_vector() for a in structure.get_atoms()])\n",
    "    com = atoms.mean(axis=0)\n",
    "    depths, protr = [], []\n",
    "    for res in structure.get_residues():\n",
    "        coords = np.array([a.get_vector() for a in res if a.element.symbol != \"H\"])\n",
    "        d = np.linalg.norm(coords - com, axis=1)\n",
    "        depths.append(d.mean())\n",
    "        protr.append(d.max() - d.mean())\n",
    "    return np.array(depths), np.array(protr)\n",
    "\n",
    "\n",
    "def compute_half_sphere_exposure(structure):\n",
    "    model = structure[0]\n",
    "    hs = HSExposureCA(model)\n",
    "    up, down = [], []\n",
    "    for res in model:\n",
    "        u, d = hs[(res, \"CA\")]\n",
    "        up.append(u)\n",
    "        down.append(d)\n",
    "    return np.array(up), np.array(down)\n",
    "\n",
    "\n",
    "def compute_contact_map(traj, thr=0.8):\n",
    "    ca = traj.topology.select(\"name CA\")\n",
    "    pairs = np.array([[i, j] for i in ca for j in ca if i < j])\n",
    "    d = md.compute_distances(traj, pairs)[0]\n",
    "    mat = np.zeros((len(ca), len(ca)), dtype=int)\n",
    "    for (i, j), dist in zip(pairs, d):\n",
    "        if dist < thr:\n",
    "            mat[i, j] = mat[j, i] = 1\n",
    "    return mat\n",
    "\n",
    "\n",
    "# --------------------------------------------------\n",
    "# 5) Driver\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "def analyze(pdb_path):\n",
    "    traj, struct = load_structures(pdb_path)\n",
    "\n",
    "    sasa, sasa_n = compute_sasa(traj, struct)\n",
    "    phi, psi, om, chi1 = compute_torsions(traj, struct)\n",
    "    hb = compute_hbonds(traj, struct)\n",
    "    sb = compute_salt_bridges(traj, struct)\n",
    "    ss = compute_ss_bridges(traj, struct)\n",
    "    pp = compute_pi_pi(traj, struct)\n",
    "    vdw = compute_vdw_contacts(traj, struct)\n",
    "    pd = compute_packing_density(traj, struct)\n",
    "    depth, protr = compute_depth_protrusion(struct)\n",
    "    hsu, hsd = compute_half_sphere_exposure(struct)\n",
    "    cmap = compute_contact_map(traj)\n",
    "\n",
    "    rows = []\n",
    "    for i, res in enumerate(struct.get_residues()):\n",
    "        aa1 = resname_to_one(res.get_resname())\n",
    "        rows.append(\n",
    "            {\n",
    "                \"chain\": res.get_parent().id,\n",
    "                \"resSeq\": res.id[1],\n",
    "                \"resName\": aa1,\n",
    "                \"ASA\": sasa[i],\n",
    "                \"ASA_norm\": sasa_n[i],\n",
    "                \"phi\": phi[i],\n",
    "                \"psi\": psi[i],\n",
    "                \"omega\": om[i],\n",
    "                \"chi1\": chi1[i],\n",
    "                \"Hbond_count\": hb[i],\n",
    "                \"salt_bridge_count\": sb[i],\n",
    "                \"ss_bridge\": ss[i],\n",
    "                \"pi_pi_count\": pp[i],\n",
    "                \"vdw_partners\": vdw[i],\n",
    "                \"packing_density\": pd[i],\n",
    "                \"hydrophobicity\": HYDRO.get(aa1, np.nan),\n",
    "                \"depth\": depth[i],\n",
    "                \"protrusion\": protr[i],\n",
    "                \"HSE_up\": hsu[i],\n",
    "                \"HSE_down\": hsd[i],\n",
    "            }\n",
    "        )\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(\"per_residue_descriptors.csv\", index=False)\n",
    "    np.save(\"contact_map.npy\", cmap)\n",
    "    print(\"→ Saved 'per_residue_descriptors.csv' and 'contact_map.npy'\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python analyze_protein.py <pdb_file>\")\n",
    "        sys.exit(1)\n",
    "    analyze(sys.argv[1])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "id": "3_giklKOXETH",
    "executionInfo": {
     "status": "error",
     "timestamp": 1745324729234,
     "user_tz": -300,
     "elapsed": 2719,
     "user": {
      "displayName": "Alexey Ganzha",
      "userId": "18251908108815644034"
     }
    },
    "outputId": "cff9b3c9-cc30-4522-d71a-5271319a512e"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Package 'biopython' not found. Installing...\n",
      "Usage: python analyze_protein.py <pdb_file>\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "SystemExit",
     "evalue": "1",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# First time only: install requirements\n",
    "!pip install numpy pandas mdtraj biopython\n",
    "\n",
    "# Import the script (it must be in the same folder or in your PYTHONPATH)\n",
    "import analyze_protein\n",
    "\n",
    "# Call the analyze function directly\n",
    "analyze_protein.analyze(\"\")  # replace with your filename"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "f19UsEiyeNqS",
    "executionInfo": {
     "status": "error",
     "timestamp": 1745325430101,
     "user_tz": -300,
     "elapsed": 6332,
     "user": {
      "displayName": "Alexey Ganzha",
      "userId": "18251908108815644034"
     }
    },
    "outputId": "a09c14ab-4517-4f09-9b7e-e2d702aafd5f"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
      "Requirement already satisfied: mdtraj in /usr/local/lib/python3.11/dist-packages (1.10.3)\n",
      "Requirement already satisfied: biopython in /usr/local/lib/python3.11/dist-packages (1.85)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mdtraj) (1.14.1)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from mdtraj) (3.2.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mdtraj) (24.2)\n",
      "Requirement already satisfied: netCDF4 in /usr/local/lib/python3.11/dist-packages (from mdtraj) (1.7.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: cftime in /usr/local/lib/python3.11/dist-packages (from netCDF4->mdtraj) (1.6.4.post1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from netCDF4->mdtraj) (2025.1.31)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-32b9720a5da6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Call the analyze function directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0manalyze_protein\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/1g4a.pdb\"\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# replace with your filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/analyze_protein.py\u001b[0m in \u001b[0;36manalyze\u001b[0;34m(pdb_path)\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0mhs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHSExposureCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m         \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CA'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/analyze_protein.py\u001b[0m in \u001b[0;36mcompute_hbonds\u001b[0;34m(traj, structure)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompute_hbonds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \"\"\"\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0mCount\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0mH\u001b[0m\u001b[0;31m‑\u001b[0m\u001b[0mbonds\u001b[0m \u001b[0mper\u001b[0m \u001b[0mresidue\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdonor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0macceptor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mWorks\u001b[0m \u001b[0meven\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mno\u001b[0m \u001b[0mH\u001b[0m\u001b[0;31m‑\u001b[0m\u001b[0mbonds\u001b[0m \u001b[0mare\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pwd\n",
    "!ls -al"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9F6V6Lye1GD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745325475941,
     "user_tz": -300,
     "elapsed": 227,
     "user": {
      "displayName": "Alexey Ganzha",
      "userId": "18251908108815644034"
     }
    },
    "outputId": "78b55833-38d2-406c-e4ce-d750d93aa8f8"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content\n",
      "total 32\n",
      "drwxr-xr-x 1 root root  4096 Apr 22 12:34 .\n",
      "drwxr-xr-x 1 root root  4096 Apr 22 12:21 ..\n",
      "-rw-r--r-- 1 root root 10704 Apr 22 12:36 analyze_protein.py\n",
      "drwxr-xr-x 4 root root  4096 Apr 17 13:36 .config\n",
      "drwxr-xr-x 2 root root  4096 Apr 22 12:34 __pycache__\n",
      "drwxr-xr-x 1 root root  4096 Apr 17 13:36 sample_data\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "%%bash\n",
    "cat > analyze_protein.py << 'EOF'\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Comprehensive per‑residue structural descriptor calculation from a PDB,\n",
    "with automatic installation of missing dependencies, and Biopython ≥ 1.80 support.\n",
    "\n",
    "Usage:\n",
    "    python analyze_protein.py <path/to/structure.pdb>\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 1) Auto‑install missing packages\n",
    "#--------------------------------------------------\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for pkg in (\"numpy\", \"pandas\", \"mdtraj\", \"biopython\"):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        print(f\"Package '{pkg}' not found. Installing...\")\n",
    "        install(pkg)\n",
    "\n",
    "# Now safe to import everything\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.PDB import PDBParser, HSExposureCA\n",
    "from Bio.Data.PDBData import protein_letters_3to1\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 2) Constants\n",
    "#--------------------------------------------------\n",
    "MAX_ASA = {\n",
    "    'A': 121, 'R': 265, 'N': 187, 'D': 187, 'C': 148, 'Q': 214, 'E': 223,\n",
    "    'G': 97,  'H': 216, 'I': 195, 'L': 191, 'K': 230, 'M': 203, 'F': 228,\n",
    "    'P': 154, 'S': 143, 'T': 163, 'W': 264, 'Y': 255, 'V': 165\n",
    "}\n",
    "\n",
    "HYDRO = {\n",
    "    'A':  1.8,  'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5,\n",
    "    'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I': 4.5,\n",
    "    'L': 3.8,  'K': -3.9, 'M': 1.9,  'F': 2.8,  'P': -1.6,\n",
    "    'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2\n",
    "}\n",
    "\n",
    "VDW_RADII = {'H': 1.2, 'C': 1.7, 'N': 1.55, 'O': 1.52, 'S': 1.8}\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 3) Helper to map 3‑letter → 1‑letter\n",
    "#--------------------------------------------------\n",
    "def resname_to_one(resname):\n",
    "    \"\"\"Convert a three‑letter residue name to one‑letter code, default 'X'.\"\"\"\n",
    "    return protein_letters_3to1.get(resname.upper(), 'X')\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 4) Core functions\n",
    "#--------------------------------------------------\n",
    "def load_structures(pdb_path):\n",
    "    traj = md.load(pdb_path)\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('X', pdb_path)\n",
    "    return traj, structure\n",
    "\n",
    "def compute_sasa(traj, structure):\n",
    "    sasa_nm2 = md.shrake_rupley(traj, probe_radius=0.14, mode='residue')\n",
    "    sasa = sasa_nm2[0] * 100.0  # nm² → Å²\n",
    "    norm = []\n",
    "    for res in structure.get_residues():\n",
    "        aa1 = resname_to_one(res.get_resname())\n",
    "        max_ = MAX_ASA.get(aa1, np.nan)\n",
    "        norm.append(sasa[res.id[1]-1] / max_ if max_ else np.nan)\n",
    "    return sasa, np.array(norm)\n",
    "\n",
    "def compute_torsions(traj, structure):\n",
    "    phi_idx, phi_vals = md.compute_phi(traj)\n",
    "    psi_idx, psi_vals = md.compute_psi(traj)\n",
    "    om_idx, om_vals   = md.compute_omega(traj)\n",
    "    chi1_idx, chi1_vals = md.compute_chi1(traj)\n",
    "\n",
    "    phi   = dict(zip(phi_idx[:,1], phi_vals[0]))\n",
    "    psi   = dict(zip(psi_idx[:,1], psi_vals[0]))\n",
    "    omega = dict(zip(om_idx[:,1],   om_vals[0]))\n",
    "    chi1  = dict(zip(chi1_idx[:,0], chi1_vals[0]))\n",
    "\n",
    "    phis = []; psis = []; omegas = []; chis = []\n",
    "    for res in structure.get_residues():\n",
    "        i = res.id[1] - 1\n",
    "        phis.append(phi.get(i, np.nan))\n",
    "        psis.append(psi.get(i, np.nan))\n",
    "        omegas.append(omega.get(i, np.nan))\n",
    "        chis.append(chi1.get(i, np.nan))\n",
    "    return (np.array(phis), np.array(psis),\n",
    "            np.array(omegas), np.array(chis))\n",
    "\n",
    "def compute_hbonds(traj, structure):\n",
    "    \"\"\"\n",
    "    Count number of H‑bonds per residue (donor + acceptor).\n",
    "    Works even if no H‑bonds are found.\n",
    "    \"\"\"\n",
    "    # MDTraj baker_hubbard may return either:\n",
    "    #   - an array of shape (n_bonds, 5)\n",
    "    #   - or a tuple (array, frequencies)\n",
    "    raw = md.baker_hubbard(traj, periodic=False)\n",
    "    # unpack\n",
    "    if isinstance(raw, tuple):\n",
    "        hbonds = raw[0]\n",
    "    else:\n",
    "        hbonds = raw\n",
    "\n",
    "    # Prepare a counter initialized to zero for every residue\n",
    "    counts = {res.id[1]: 0 for res in structure.get_residues()}\n",
    "\n",
    "    # If hbonds is empty, this loop simply does nothing\n",
    "    for bond in hbonds:\n",
    "        donor_idx   = int(bond[0])\n",
    "        acceptor_idx= int(bond[2])\n",
    "        dres = traj.topology.atom(donor_idx).residue.id\n",
    "        ares = traj.topology.atom(acceptor_idx).residue.id\n",
    "        counts[dres] += 1\n",
    "        counts[ares] += 1\n",
    "\n",
    "    # Build and return a numpy array in structure order\n",
    "    return np.array([counts[r.id[1]] for r in structure.get_residues()])\n",
    "\n",
    "def compute_salt_bridges(traj, structure, cutoff=0.4):\n",
    "    neg = traj.topology.select(\"resname ASP GLU and name OD1 OD2 OE1 OE2\")\n",
    "    pos = traj.topology.select(\"resname LYS ARG HIS and name NZ NH1 NH2 NE\")\n",
    "    d = md.compute_distances(traj, np.array([[i,j] for i in neg for j in pos]))[0]\n",
    "    pairs = np.where(d < cutoff)\n",
    "    counts = {r.id[1]:0 for r in structure.get_residues()}\n",
    "    for ni, pi in zip(*pairs):\n",
    "        ri = traj.topology.atom(neg[ni]).residue.id\n",
    "        rj = traj.topology.atom(pos[pi]).residue.id\n",
    "        counts[ri] += 1; counts[rj] += 1\n",
    "    return np.array([counts[r.id[1]] for r in structure.get_residues()])\n",
    "\n",
    "def compute_ss_bridges(traj, structure, cutoff=0.22):\n",
    "    sg = traj.topology.select(\"resname CYS and name SG\")\n",
    "    d = md.compute_distances(traj, np.array([[i,j] for i in sg for j in sg]))[0]\n",
    "    pairs = np.where((d < cutoff) & (d > 0))\n",
    "    bonded = set()\n",
    "    for i, j in zip(*pairs):\n",
    "        bonded.update([\n",
    "            traj.topology.atom(sg[i]).residue.id,\n",
    "            traj.topology.atom(sg[j]).residue.id\n",
    "        ])\n",
    "    return np.array([1 if r.id[1] in bonded else 0 for r in structure.get_residues()])\n",
    "\n",
    "def compute_pi_pi(traj, structure, cutoff=0.7):\n",
    "    arom = {\n",
    "      'PHE':('CG','CD1','CD2','CE1','CE2','CZ'),\n",
    "      'TYR':('CG','CD1','CD2','CE1','CE2','CZ'),\n",
    "      'TRP':('CG','CD1','CD2','NE1','CE2','CE3','CZ2','CZ3','CH2')\n",
    "    }\n",
    "    cents = {}\n",
    "    for chain in structure:\n",
    "        for res in chain:\n",
    "            name = res.get_resname()\n",
    "            if name in arom:\n",
    "                coords = np.array([a.get_vector() for a in res\n",
    "                                   if a.get_name() in arom[name]])\n",
    "                cents[res.id[1]] = coords.mean(axis=0)\n",
    "    counts = {r.id[1]:0 for r in structure.get_residues()}\n",
    "    keys = list(cents)\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(i+1, len(keys)):\n",
    "            if np.linalg.norm(cents[keys[i]]-cents[keys[j]]) < cutoff*10:\n",
    "                counts[keys[i]] += 1; counts[keys[j]] += 1\n",
    "    return np.array([counts[r.id[1]] for r in structure.get_residues()])\n",
    "\n",
    "def compute_vdw_contacts(traj, structure, extra=0.05):\n",
    "    coords = traj.xyz[0] * 10\n",
    "    elems  = [a.element.symbol for a in traj.topology.atoms]\n",
    "    radii  = np.array([VDW_RADII.get(e,1.5) for e in elems])\n",
    "    pairs = np.array([[i,j] for i in range(len(coords)) for j in range(i+1, len(coords))])\n",
    "    dists = np.linalg.norm(coords[pairs[:,0]]-coords[pairs[:,1]], axis=1)\n",
    "    thresh = radii[pairs[:,0]] + radii[pairs[:,1]] + extra\n",
    "    hits   = pairs[dists < thresh]\n",
    "    resmap = {a.index:a.residue.id[1] for a in traj.topology.atoms}\n",
    "    conts  = {r.id[1]:set() for r in structure.get_residues()}\n",
    "    for i,j in hits:\n",
    "        ri, rj = resmap[i], resmap[j]\n",
    "        if ri!=rj:\n",
    "            conts[ri].add(rj); conts[rj].add(ri)\n",
    "    return np.array([len(conts[r.id[1]]) for r in structure.get_residues()])\n",
    "\n",
    "def compute_packing_density(traj, structure, r=1.0):\n",
    "    ca = traj.topology.select(\"name CA\")\n",
    "    coords = traj.xyz[0]\n",
    "    vol = 4/3 * np.pi * r**3 * 1e3\n",
    "    pd = []\n",
    "    for idx, res in enumerate(structure.get_residues()):\n",
    "        d = np.linalg.norm((coords - coords[0][ca[idx]]), axis=2) * 10\n",
    "        pd.append((np.sum(d<r*10)-1)/vol)\n",
    "    return np.array(pd)\n",
    "\n",
    "def compute_depth_protrusion(structure):\n",
    "    atoms = np.array([a.get_vector() for a in structure.get_atoms()])\n",
    "    com   = atoms.mean(axis=0)\n",
    "    depths, protr = [], []\n",
    "    for res in structure.get_residues():\n",
    "        coords = np.array([a.get_vector() for a in res if a.element.symbol!='H'])\n",
    "        d = np.linalg.norm(coords-com, axis=1)\n",
    "        depths.append(d.mean()); protr.append(d.max()-d.mean())\n",
    "    return np.array(depths), np.array(protr)\n",
    "\n",
    "def compute_half_sphere_exposure(structure):\n",
    "    model = structure[0]\n",
    "    hs = HSExposureCA(model)\n",
    "    up, down = [], []\n",
    "    for res in model:\n",
    "        u, d = hs[(res,'CA')]\n",
    "        up.append(u); down.append(d)\n",
    "    return np.array(up), np.array(down)\n",
    "\n",
    "def compute_contact_map(traj, thr=0.8):\n",
    "    ca = traj.topology.select(\"name CA\")\n",
    "    pairs = np.array([[i,j] for i in ca for j in ca if i<j])\n",
    "    d = md.compute_distances(traj, pairs)[0]\n",
    "    mat = np.zeros((len(ca), len(ca)), dtype=int)\n",
    "    for (i,j), dist in zip(pairs, d):\n",
    "        if dist < thr: mat[i,j] = mat[j,i] = 1\n",
    "    return mat\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 5) Driver\n",
    "#--------------------------------------------------\n",
    "def analyze(pdb_path):\n",
    "    traj, struct = load_structures(pdb_path)\n",
    "\n",
    "    sasa, sasa_n    = compute_sasa(traj, struct)\n",
    "    phi, psi, om, chi1 = compute_torsions(traj, struct)\n",
    "    hb   = compute_hbonds(traj, struct)\n",
    "    sb   = compute_salt_bridges(traj, struct)\n",
    "    ss   = compute_ss_bridges(traj, struct)\n",
    "    pp   = compute_pi_pi(traj, struct)\n",
    "    vdw  = compute_vdw_contacts(traj, struct)\n",
    "    pd   = compute_packing_density(traj, struct)\n",
    "    depth, protr    = compute_depth_protrusion(struct)\n",
    "    hsu, hsd        = compute_half_sphere_exposure(struct)\n",
    "    cmap            = compute_contact_map(traj)\n",
    "\n",
    "    rows = []\n",
    "    for i, res in enumerate(struct.get_residues()):\n",
    "        aa1 = resname_to_one(res.get_resname())\n",
    "        rows.append({\n",
    "            'chain':             res.get_parent().id,\n",
    "            'resSeq':            res.id[1],\n",
    "            'resName':           aa1,\n",
    "            'ASA':               sasa[i],\n",
    "            'ASA_norm':          sasa_n[i],\n",
    "            'phi':               phi[i],\n",
    "            'psi':               psi[i],\n",
    "            'omega':             om[i],\n",
    "            'chi1':              chi1[i],\n",
    "            'Hbond_count':       hb[i],\n",
    "            'salt_bridge_count': sb[i],\n",
    "            'ss_bridge':         ss[i],\n",
    "            'pi_pi_count':       pp[i],\n",
    "            'vdw_partners':      vdw[i],\n",
    "            'packing_density':   pd[i],\n",
    "            'hydrophobicity':    HYDRO.get(aa1, np.nan),\n",
    "            'depth':             depth[i],\n",
    "            'protrusion':        protr[i],\n",
    "            'HSE_up':            hsu[i],\n",
    "            'HSE_down':          hsd[i]\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv('per_residue_descriptors.csv', index=False)\n",
    "    np.save('contact_map.npy', cmap)\n",
    "    print(\"→ Saved 'per_residue_descriptors.csv' and 'contact_map.npy'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) != 2:\n",
    "        print(\"Usage: python analyze_protein.py <pdb_file>\")\n",
    "        sys.exit(1)\n",
    "    analyze(sys.argv[1])\n",
    "EOF"
   ],
   "metadata": {
    "id": "qNR6atC3fDi8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1745325419474,
     "user_tz": -300,
     "elapsed": 6,
     "user": {
      "displayName": "Alexey Ganzha",
      "userId": "18251908108815644034"
     }
    }
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile analyze_protein.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Comprehensive per-residue structural descriptor calculation from a PDB,\n",
    "with automatic installation of missing dependencies, and Biopython ≥ 1.80 support.\n",
    "\n",
    "Usage:\n",
    "    python analyze_protein.py <path/to/structure.pdb>\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 1) Auto-install missing packages\n",
    "#--------------------------------------------------\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for pkg in (\"numpy\", \"pandas\", \"mdtraj\", \"biopython\"):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        print(f\"Package '{pkg}' not found. Installing...\")\n",
    "        install(pkg)\n",
    "\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.PDB import PDBParser, HSExposureCA\n",
    "from Bio.Data.PDBData import protein_letters_3to1\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 2) Constants\n",
    "#--------------------------------------------------\n",
    "MAX_ASA = {\n",
    "    'A': 121, 'R': 265, 'N': 187, 'D': 187, 'C': 148, 'Q': 214, 'E': 223,\n",
    "    'G': 97,  'H': 216, 'I': 195, 'L': 191, 'K': 230, 'M': 203, 'F': 228,\n",
    "    'P': 154, 'S': 143, 'T': 163, 'W': 264, 'Y': 255, 'V': 165\n",
    "}\n",
    "\n",
    "HYDRO = {\n",
    "    'A': 1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5, 'Q': -3.5, 'E': -3.5,\n",
    "    'G': -0.4, 'H': -3.2, 'I': 4.5, 'L': 3.8, 'K': -3.9, 'M': 1.9, 'F': 2.8,\n",
    "    'P': -1.6, 'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2\n",
    "}\n",
    "\n",
    "VDW_RADII = {'H': 1.2, 'C': 1.7, 'N': 1.55, 'O': 1.52, 'S': 1.8}\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 3) Helper: 3-letter to 1-letter\n",
    "#--------------------------------------------------\n",
    "def resname_to_one(resname):\n",
    "    return protein_letters_3to1.get(resname.upper(), 'X')\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 4) Core functions\n",
    "#--------------------------------------------------\n",
    "def load_structures(pdb_path):\n",
    "    traj = md.load(pdb_path)\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('X', pdb_path)\n",
    "    return traj, structure\n",
    "\n",
    "def compute_sasa(traj, structure):\n",
    "    sasa_nm2 = md.shrake_rupley(traj, probe_radius=0.14, mode='residue')\n",
    "    sasa = sasa_nm2[0] * 100.0\n",
    "    residues = list(structure.get_residues())\n",
    "    norm = []\n",
    "    for i, res in enumerate(residues):\n",
    "        aa1 = resname_to_one(res.get_resname())\n",
    "        max_ = MAX_ASA.get(aa1, np.nan)\n",
    "        norm.append(sasa[i] / max_ if max_ else np.nan)\n",
    "    return sasa, np.array(norm)\n",
    "\n",
    "def compute_torsions(traj, structure):\n",
    "    phi_idx, phi_vals = md.compute_phi(traj)\n",
    "    psi_idx, psi_vals = md.compute_psi(traj)\n",
    "    om_idx, om_vals   = md.compute_omega(traj)\n",
    "    chi1_idx, chi1_vals = md.compute_chi1(traj)\n",
    "\n",
    "    phi   = dict(zip(phi_idx[:, 1], phi_vals[0]))\n",
    "    psi   = dict(zip(psi_idx[:, 1], psi_vals[0]))\n",
    "    omega = dict(zip(om_idx[:, 1], om_vals[0]))\n",
    "    chi1  = dict(zip(chi1_idx[:, 0], chi1_vals[0]))\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(list(structure.get_residues()))):\n",
    "        results.append([\n",
    "            phi.get(i, np.nan), psi.get(i, np.nan),\n",
    "            omega.get(i, np.nan), chi1.get(i, np.nan)\n",
    "        ])\n",
    "    return map(np.array, zip(*results))\n",
    "\n",
    "def compute_hbonds(traj, structure):\n",
    "    hbonds = md.baker_hubbard(traj, periodic=False)\n",
    "    counts = {res.index: 0 for res in traj.topology.residues}\n",
    "    for i, j, k in hbonds:\n",
    "        counts[traj.topology.atom(i).residue.index] += 1\n",
    "        counts[traj.topology.atom(k).residue.index] += 1\n",
    "    return np.array([counts[i] for i in range(len(counts))])\n",
    "\n",
    "def compute_salt_bridges(traj, structure, cutoff=0.4):\n",
    "    acidic = ['ASP', 'GLU']\n",
    "    basic = ['ARG', 'LYS', 'HIS']\n",
    "    pairs = []\n",
    "    for i, a1 in enumerate(traj.topology.atoms):\n",
    "        if a1.residue.name in acidic and a1.name in ['OD1', 'OD2', 'OE1', 'OE2']:\n",
    "            for j, a2 in enumerate(traj.topology.atoms):\n",
    "                if a2.residue.name in basic and a2.name in ['NZ', 'NH1', 'NH2', 'ND1', 'NE2']:\n",
    "                    pairs.append([i, j])\n",
    "    if not pairs:\n",
    "        return np.zeros(len(list(structure.get_residues())), dtype=int)\n",
    "    dists = md.compute_distances(traj, pairs)[0]\n",
    "    from collections import defaultdict\n",
    "    counts = defaultdict(int)\n",
    "    for idx, (i, j) in enumerate(pairs):\n",
    "        if dists[idx] < cutoff:\n",
    "            counts[traj.topology.atom(i).residue.index] += 1\n",
    "            counts[traj.topology.atom(j).residue.index] += 1\n",
    "    result = np.zeros(len(list(structure.get_residues())), dtype=int)\n",
    "    for k, v in counts.items():\n",
    "        result[k] = v\n",
    "    return result\n",
    "\n",
    "def compute_ss_bridges(traj, structure, cutoff=0.22):\n",
    "    sg = traj.topology.select(\"resname CYS and name SG\")\n",
    "    pairs = np.array([[i, j] for i in sg for j in sg if i < j])\n",
    "    if not len(pairs): return np.zeros(len(list(structure.get_residues())), dtype=int)\n",
    "    d = md.compute_distances(traj, pairs)[0]\n",
    "    bonded = set()\n",
    "    for (i, j), dist in zip(pairs, d):\n",
    "        if 0 < dist < cutoff:\n",
    "            bonded.update([traj.topology.atom(i).residue.index,\n",
    "                           traj.topology.atom(j).residue.index])\n",
    "    return np.array([1 if i in bonded else 0 for i in range(len(list(structure.get_residues())))])\n",
    "\n",
    "def compute_pi_pi(traj, structure, cutoff=0.7):\n",
    "    arom = {\n",
    "        'PHE': ('CG','CD1','CD2','CE1','CE2','CZ'),\n",
    "        'TYR': ('CG','CD1','CD2','CE1','CE2','CZ'),\n",
    "        'TRP': ('CG','CD1','CD2','NE1','CE2','CE3','CZ2','CZ3','CH2')\n",
    "    }\n",
    "    cents = {}\n",
    "    for chain in structure[0]:\n",
    "        for res in chain:\n",
    "            name = res.get_resname()\n",
    "            if name in arom:\n",
    "                coords = [a.get_coord() for a in res if a.get_name() in arom[name]]\n",
    "                if coords:\n",
    "                    cents[res.id[1]] = np.mean(coords, axis=0)\n",
    "    keys = list(cents)\n",
    "    counts = {k: 0 for k in keys}\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(i+1, len(keys)):\n",
    "            if np.linalg.norm(cents[keys[i]] - cents[keys[j]]) < cutoff * 10:\n",
    "                counts[keys[i]] += 1\n",
    "                counts[keys[j]] += 1\n",
    "    return np.array([counts.get(res.id[1], 0) for res in structure.get_residues()])\n",
    "\n",
    "def compute_vdw_contacts(traj, structure, extra=0.05):\n",
    "    coords = traj.xyz[0] * 10\n",
    "    elems = [a.element.symbol for a in traj.topology.atoms]\n",
    "    radii = np.array([VDW_RADII.get(e, 1.5) for e in elems])\n",
    "    pairs = np.array([[i, j] for i in range(len(coords)) for j in range(i+1, len(coords))])\n",
    "    dists = np.linalg.norm(coords[pairs[:,0]] - coords[pairs[:,1]], axis=1)\n",
    "    thresh = radii[pairs[:,0]] + radii[pairs[:,1]] + extra\n",
    "    hits = pairs[dists < thresh]\n",
    "    resmap = {a.index: a.residue.index for a in traj.topology.atoms}\n",
    "    residues = list(structure.get_residues())\n",
    "    conts = {i: set() for i in range(len(residues))}\n",
    "    for i, j in hits:\n",
    "        ri, rj = resmap[i], resmap[j]\n",
    "        if ri != rj:\n",
    "            conts[ri].add(rj)\n",
    "            conts[rj].add(ri)\n",
    "    return np.array([len(conts[i]) for i in range(len(structure.get_residues()))])\n",
    "\n",
    "def compute_packing_density(traj, structure, r=1.0):\n",
    "    ca = traj.topology.select(\"name CA\")\n",
    "    coords = traj.xyz[0][ca] * 10\n",
    "    vol = (4/3) * np.pi * (r ** 3)\n",
    "    pd = []\n",
    "    for i in range(len(coords)):\n",
    "        d = np.linalg.norm(coords - coords[i], axis=1)\n",
    "        pd.append((np.sum(d < r * 10) - 1) / vol)\n",
    "    return np.array(pd)\n",
    "\n",
    "def compute_depth_protrusion(structure):\n",
    "    atoms = np.array([a.get_coord() for a in structure.get_atoms() if a.element != 'H'])\n",
    "    com = atoms.mean(axis=0)\n",
    "    depths, protr = [], []\n",
    "    for res in structure.get_residues():\n",
    "        coords = np.array([a.get_coord() for a in res if a.element != 'H'])\n",
    "        d = np.linalg.norm(coords - com, axis=1)\n",
    "        depths.append(d.mean()); protr.append(d.max() - d.mean())\n",
    "    return np.array(depths), np.array(protr)\n",
    "\n",
    "def compute_half_sphere_exposure(structure):\n",
    "    model = structure[0]\n",
    "    hs = HSExposureCA(model)\n",
    "    up, down = [], []\n",
    "    for res in model:\n",
    "        try:\n",
    "            u, d = hs[(res, 'CA')]\n",
    "        except KeyError:\n",
    "            u, d = np.nan, np.nan\n",
    "        up.append(u)\n",
    "        down.append(d)\n",
    "    return np.array(up), np.array(down)\n",
    "\n",
    "def compute_contact_map(traj, thr=0.8):\n",
    "    ca = traj.topology.select(\"name CA\")\n",
    "    pairs = np.array([[i, j] for i in ca for j in ca if i < j])\n",
    "    d = md.compute_distances(traj, pairs)[0]\n",
    "    n = len(ca)\n",
    "    mat = np.zeros((n, n), dtype=int)\n",
    "    for (i, j), dist in zip(pairs, d):\n",
    "        if dist < thr:\n",
    "            i_idx = np.where(ca == i)[0][0]\n",
    "            j_idx = np.where(ca == j)[0][0]\n",
    "            mat[i_idx, j_idx] = mat[j_idx, i_idx] = 1\n",
    "    return mat\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 5) Driver\n",
    "#--------------------------------------------------\n",
    "def analyze(pdb_path):\n",
    "    traj, struct = load_structures(pdb_path)\n",
    "    sasa, sasa_n = compute_sasa(traj, struct)\n",
    "    phi, psi, om, chi1 = compute_torsions(traj, struct)\n",
    "    hb = compute_hbonds(traj, struct)\n",
    "    sb = compute_salt_bridges(traj, struct)\n",
    "    ss = compute_ss_bridges(traj, struct)\n",
    "    pp = compute_pi_pi(traj, struct)\n",
    "    vdw = compute_vdw_contacts(traj, struct)\n",
    "    pd = compute_packing_density(traj, struct)\n",
    "    depth, protr = compute_depth_protrusion(struct)\n",
    "    hsu, hsd = compute_half_sphere_exposure(struct)\n",
    "    cmap = compute_contact_map(traj)\n",
    "\n",
    "    rows = []\n",
    "    for i, res in enumerate(struct.get_residues()):\n",
    "        aa1 = resname_to_one(res.get_resname())\n",
    "        rows.append({\n",
    "            'chain': res.get_parent().id,\n",
    "            'resSeq': res.id[1],\n",
    "            'resName': aa1,\n",
    "            'ASA': sasa[i],\n",
    "            'ASA_norm': sasa_n[i],\n",
    "            'phi': phi[i],\n",
    "            'psi': psi[i],\n",
    "            'omega': om[i],\n",
    "            'chi1': chi1[i],\n",
    "            'Hbond_count': hb[i],\n",
    "            'salt_bridge_count': sb[i],\n",
    "            'ss_bridge': ss[i],\n",
    "            'pi_pi_count': pp[i],\n",
    "            'vdw_partners': vdw[i],\n",
    "            'packing_density': pd[i],\n",
    "            'hydrophobicity': HYDRO.get(aa1, np.nan),\n",
    "            'depth': depth[i],\n",
    "            'protrusion': protr[i],\n",
    "            'HSE_up': hsu[i],\n",
    "            'HSE_down': hsd[i]\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv('per_residue_descriptors.csv', index=False)\n",
    "    np.save('contact_map.npy', cmap)\n",
    "    print(\"→ Saved 'per_residue_descriptors.csv' and 'contact_map.npy'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) == 2:\n",
    "        analyze(sys.argv[1])"
   ],
   "metadata": {
    "id": "fVjhvr6MbXJ9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile analyze_protein.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Comprehensive per-residue structural descriptor calculation from a PDB,\n",
    "with automatic installation of missing dependencies, and Biopython ≥ 1.80 support.\n",
    "\n",
    "Usage:\n",
    "    python analyze_protein.py <path/to/structure.pdb>\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 1) Auto‑install missing packages\n",
    "#--------------------------------------------------\n",
    "def install(pkg):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for pkg in (\"numpy\", \"pandas\", \"mdtraj\", \"biopython\"):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "    except ImportError:\n",
    "        print(f\"Package '{pkg}' not found. Installing...\")\n",
    "        install(pkg)\n",
    "\n",
    "import mdtraj as md\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from Bio.PDB import PDBParser, HSExposureCA\n",
    "from Bio.Data.PDBData import protein_letters_3to1\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 2) Constants\n",
    "#--------------------------------------------------\n",
    "MAX_ASA = {\n",
    "    'A': 121, 'R': 265, 'N': 187, 'D': 187, 'C': 148, 'Q': 214, 'E': 223,\n",
    "    'G': 97,  'H': 216, 'I': 195, 'L': 191, 'K': 230, 'M': 203, 'F': 228,\n",
    "    'P': 154, 'S': 143, 'T': 163, 'W': 264, 'Y': 255, 'V': 165\n",
    "}\n",
    "\n",
    "HYDRO = {\n",
    "    'A':  1.8,  'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5,\n",
    "    'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I': 4.5,\n",
    "    'L': 3.8,  'K': -3.9, 'M': 1.9,  'F': 2.8,  'P': -1.6,\n",
    "    'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2\n",
    "}\n",
    "\n",
    "VDW_RADII = {'H': 1.2, 'C': 1.7, 'N': 1.55, 'O': 1.52, 'S': 1.8}\n",
    "\n",
    "def resname_to_one(resname):\n",
    "    return protein_letters_3to1.get(resname.upper(), 'X')\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 3) Core Functions\n",
    "#--------------------------------------------------\n",
    "def load_structures(pdb_path):\n",
    "    traj = md.load(pdb_path)\n",
    "    parser = PDBParser(QUIET=True)\n",
    "    structure = parser.get_structure('X', pdb_path)\n",
    "    return traj, structure\n",
    "\n",
    "def compute_sasa(traj, structure):\n",
    "    sasa_nm2 = md.shrake_rupley(traj, probe_radius=0.14, mode='residue')\n",
    "    sasa = sasa_nm2[0] * 100.0\n",
    "    residues = list(structure.get_residues())\n",
    "    norm = []\n",
    "    for res in residues:\n",
    "        aa1 = resname_to_one(res.get_resname())\n",
    "        max_ = MAX_ASA.get(aa1, np.nan)\n",
    "        norm.append(sasa[res.id[1]-1] / max_ if max_ else np.nan)\n",
    "    return sasa, np.array(norm)\n",
    "\n",
    "def compute_torsions(traj, structure):\n",
    "    phi_idx, phi_vals = md.compute_phi(traj)\n",
    "    psi_idx, psi_vals = md.compute_psi(traj)\n",
    "    om_idx, om_vals   = md.compute_omega(traj)\n",
    "    chi1_idx, chi1_vals = md.compute_chi1(traj)\n",
    "\n",
    "    phi   = dict(zip(phi_idx[:,1], phi_vals[0]))\n",
    "    psi   = dict(zip(psi_idx[:,1], psi_vals[0]))\n",
    "    omega = dict(zip(om_idx[:,1],   om_vals[0]))\n",
    "    chi1  = dict(zip(chi1_idx[:,0], chi1_vals[0]))\n",
    "\n",
    "    results = list(structure.get_residues())\n",
    "    phis = []; psis = []; omegas = []; chis = []\n",
    "    for res in results:\n",
    "        i = res.id[1] - 1\n",
    "        phis.append(phi.get(i, np.nan))\n",
    "        psis.append(psi.get(i, np.nan))\n",
    "        omegas.append(omega.get(i, np.nan))\n",
    "        chis.append(chi1.get(i, np.nan))\n",
    "    return (np.array(phis), np.array(psis),\n",
    "            np.array(omegas), np.array(chis))\n",
    "\n",
    "def compute_hbonds(traj, structure):\n",
    "    raw = md.baker_hubbard(traj, periodic=False)\n",
    "    hbonds = raw[0] if isinstance(raw, tuple) else raw\n",
    "    residues = list(structure.get_residues())\n",
    "    counts = {res.id[1]: 0 for res in residues}\n",
    "    for bond in hbonds:\n",
    "        dres = traj.topology.atom(int(bond[0])).residue.index\n",
    "        ares = traj.topology.atom(int(bond[2])).residue.index\n",
    "        counts[dres] += 1\n",
    "        counts[ares] += 1\n",
    "    return np.array([counts.get(i, 0) for i in range(len(residues))])\n",
    "\n",
    "def compute_salt_bridges(traj, structure, cutoff=0.4):\n",
    "    from collections import defaultdict\n",
    "    acidic = ['ASP', 'GLU']\n",
    "    basic = ['ARG', 'LYS', 'HIS']\n",
    "\n",
    "    pairs = []\n",
    "    for i, atom_i in enumerate(traj.topology.atoms):\n",
    "        if atom_i.residue.name in acidic and atom_i.name in ['OD1', 'OD2', 'OE1', 'OE2']:\n",
    "            for j, atom_j in enumerate(traj.topology.atoms):\n",
    "                if atom_j.residue.name in basic and atom_j.name in ['NZ', 'NH1', 'NH2', 'ND1', 'NE2']:\n",
    "                    pairs.append([i, j])\n",
    "\n",
    "    residues = list(structure.get_residues())\n",
    "    if not pairs:\n",
    "        return np.zeros(len(residues), dtype=int)\n",
    "\n",
    "    distances = md.compute_distances(traj, pairs)[0]\n",
    "    counts = defaultdict(int)\n",
    "    for idx, (i, j) in enumerate(pairs):\n",
    "        if distances[idx] < cutoff:\n",
    "            res_i = traj.topology.atom(i).residue.index\n",
    "            res_j = traj.topology.atom(j).residue.index\n",
    "            counts[res_i] += 1\n",
    "            counts[res_j] += 1\n",
    "\n",
    "    result = np.zeros(len(residues), dtype=int)\n",
    "    for i, c in counts.items():\n",
    "        result[i] = c\n",
    "    return result\n",
    "\n",
    "def compute_ss_bridges(traj, structure, cutoff=0.22):\n",
    "    sg = traj.topology.select(\"resname CYS and name SG\")\n",
    "    d = md.compute_distances(traj, np.array([[i,j] for i in sg for j in sg]))[0]\n",
    "    pairs = np.where((d < cutoff) & (d > 0))\n",
    "    bonded = set()\n",
    "    for i, j in zip(*pairs):\n",
    "        bonded.update([\n",
    "            traj.topology.atom(sg[i]).residue.index,\n",
    "            traj.topology.atom(sg[j]).residue.index\n",
    "        ])\n",
    "    residues = list(structure.get_residues())\n",
    "    return np.array([1 if i in bonded else 0 for i in range(len(residues))])\n",
    "\n",
    "def compute_pi_pi(traj, structure, cutoff=0.7):\n",
    "    arom = {\n",
    "        'PHE': ('CG','CD1','CD2','CE1','CE2','CZ'),\n",
    "        'TYR': ('CG','CD1','CD2','CE1','CE2','CZ'),\n",
    "        'TRP': ('CG','CD1','CD2','NE1','CE2','CE3','CZ2','CZ3','CH2')\n",
    "    }\n",
    "    cents = {}\n",
    "    residues = list(structure.get_residues())\n",
    "    for chain in structure[0]:\n",
    "        for res in chain:\n",
    "            name = res.get_resname()\n",
    "            if name in arom:\n",
    "                coords = np.array([a.get_vector() for a in res if a.get_name() in arom[name]])\n",
    "                if len(coords):\n",
    "                    cents[res.id[1]] = coords.mean(axis=0)\n",
    "    counts = {r.id[1]: 0 for r in residues}\n",
    "    keys = list(cents.keys())\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(i+1, len(keys)):\n",
    "            if np.linalg.norm(cents[keys[i]] - cents[keys[j]]) < cutoff * 10:\n",
    "                counts[keys[i]] += 1\n",
    "                counts[keys[j]] += 1\n",
    "    return np.array([counts[r.id[1]] for r in residues])\n",
    "\n",
    "def compute_vdw_contacts(traj, structure, extra=0.05):\n",
    "    coords = traj.xyz[0] * 10\n",
    "    elems  = [a.element.symbol for a in traj.topology.atoms]\n",
    "    radii  = np.array([VDW_RADII.get(e,1.5) for e in elems])\n",
    "    pairs = np.array([[i,j] for i in range(len(coords)) for j in range(i+1, len(coords))])\n",
    "    dists = np.linalg.norm(coords[pairs[:,0]]-coords[pairs[:,1]], axis=1)\n",
    "    thresh = radii[pairs[:,0]] + radii[pairs[:,1]] + extra\n",
    "    hits   = pairs[dists < thresh]\n",
    "    residues = list(structure.get_residues())\n",
    "    resmap = {a.index:a.residue.index for a in traj.topology.atoms}\n",
    "    conts  = {i:set() for i in range(len(residues))}\n",
    "    for i,j in hits:\n",
    "        ri, rj = resmap[i], resmap[j]\n",
    "        if ri != rj:\n",
    "            conts[ri].add(rj); conts[rj].add(ri)\n",
    "    return np.array([len(conts[i]) for i in range(len(residues))])\n",
    "\n",
    "def compute_packing_density(traj, structure, r=1.0):\n",
    "    ca_indices = traj.topology.select(\"name CA\")\n",
    "    coords = traj.xyz[0][ca_indices]  # only CA atoms\n",
    "    vol = 4/3 * np.pi * r**3 * 1e3\n",
    "    pdc = np.zeros(len(list(structure.get_residues())))  # full-length array with zeros\n",
    "    ca_res_map = {i: atom.residue.index for i, atom in enumerate(traj.topology.atoms) if atom.name == \"CA\"}\n",
    "\n",
    "    for idx, res_idx in enumerate(ca_res_map.values()):\n",
    "        d = np.linalg.norm(coords - coords[idx], axis=1) * 10\n",
    "        pdc[res_idx] = (np.sum(d < r * 10) - 1) / vol  # exclude self\n",
    "    return pdc\n",
    "\n",
    "def compute_depth_protrusion(structure):\n",
    "    atoms = np.array([a.get_vector().get_array() for a in structure.get_atoms()])\n",
    "    com   = atoms.mean(axis=0)\n",
    "    depths, protr = [], []\n",
    "    for res in structure.get_residues():\n",
    "        coords = np.array([a.get_vector().get_array() for a in res if a.element != 'H'])\n",
    "        d = np.linalg.norm(coords - com, axis=1)\n",
    "        depths.append(d.mean())\n",
    "        protr.append(d.max() - d.mean())\n",
    "    return np.array(depths), np.array(protr)\n",
    "\n",
    "def compute_half_sphere_exposure(structure):\n",
    "    model = structure[0]\n",
    "    hs = HSExposureCA(model)\n",
    "    up, down = [], []\n",
    "    for res in model.get_residues():\n",
    "        try:\n",
    "            u, d = hs[(res, 'CA')]\n",
    "            up.append(u)\n",
    "            down.append(d)\n",
    "        except KeyError:\n",
    "            up.append(np.nan)\n",
    "            down.append(np.nan)\n",
    "    return np.array(up), np.array(down)\n",
    "\n",
    "def compute_contact_map(traj, thr=0.8):\n",
    "    ca = traj.topology.select(\"name CA\")\n",
    "    index_map = {atom_idx: i for i, atom_idx in enumerate(ca)}\n",
    "    pairs = np.array([[i, j] for i in ca for j in ca if i < j])\n",
    "    dists = md.compute_distances(traj, pairs)[0]\n",
    "\n",
    "    mat = np.zeros((len(ca), len(ca)), dtype=int)\n",
    "    for (i_atom, j_atom), dist in zip(pairs, dists):\n",
    "        i = index_map[i_atom]\n",
    "        j = index_map[j_atom]\n",
    "        if dist < thr:\n",
    "            mat[i, j] = mat[j, i] = 1\n",
    "    return mat\n",
    "\n",
    "#--------------------------------------------------\n",
    "# 4) Driver\n",
    "#--------------------------------------------------\n",
    "def analyze(pdb_path):\n",
    "    traj, struct = load_structures(pdb_path)\n",
    "    residues = list(struct.get_residues())\n",
    "\n",
    "    sasa, sasa_n    = compute_sasa(traj, struct)\n",
    "    phi, psi, om, chi1 = compute_torsions(traj, struct)\n",
    "    hb   = compute_hbonds(traj, struct)\n",
    "    sb   = compute_salt_bridges(traj, struct)\n",
    "    ss   = compute_ss_bridges(traj, struct)\n",
    "    pp   = compute_pi_pi(traj, struct)\n",
    "    vdw  = compute_vdw_contacts(traj, struct)\n",
    "    pdc   = compute_packing_density(traj, struct)\n",
    "    depth, protr    = compute_depth_protrusion(struct)\n",
    "    hsu, hsd        = compute_half_sphere_exposure(struct)\n",
    "    cmap            = compute_contact_map(traj)\n",
    "\n",
    "    rows = []\n",
    "    for i, res in enumerate(residues):\n",
    "        aa1 = resname_to_one(res.get_resname())\n",
    "        rows.append({\n",
    "            'chain':             res.get_parent().id,\n",
    "            'resSeq':            res.id[1],\n",
    "            'resName':           aa1,\n",
    "            'ASA':               sasa[i],\n",
    "            'ASA_norm':          sasa_n[i],\n",
    "            'phi':               phi[i],\n",
    "            'psi':               psi[i],\n",
    "            'omega':             om[i],\n",
    "            'chi1':              chi1[i],\n",
    "            'Hbond_count':       hb[i],\n",
    "            'salt_bridge_count': sb[i],\n",
    "            'ss_bridge':         ss[i],\n",
    "            'pi_pi_count':       pp[i],\n",
    "            'vdw_partners':      vdw[i],\n",
    "            'packing_density':   pdc[i],\n",
    "            'hydrophobicity':    HYDRO.get(aa1, np.nan),\n",
    "            'depth':             depth[i],\n",
    "            'protrusion':        protr[i],\n",
    "            'HSE_up':            hsu[i],\n",
    "            'HSE_down':          hsd[i]\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv('per_residue_descriptors.csv', index=False)\n",
    "    np.save('contact_map.npy', cmap)\n",
    "    print(\"→ Saved 'per_residue_descriptors.csv' and 'contact_map.npy'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if len(sys.argv) == 2:\n",
    "        analyze(sys.argv[1])"
   ],
   "metadata": {
    "id": "2qDGylgOwrst"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "%%writefile analyze_protein.py\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Comprehensive per-residue and global structural descriptor analysis from a PDB file.\n",
    "Requires: mdtraj, biopython, pandas, numpy, pdbfixer, openmm\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install(pkg): subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", pkg])\n",
    "\n",
    "for pkg in (\"numpy\", \"pandas\", \"mdtraj\", \"biopython\", \"pdbfixer\", \"openmm\"):\n",
    "    try: __import__(pkg)\n",
    "    except ImportError: install(pkg)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mdtraj as md\n",
    "from Bio.PDB import PDBParser, HSExposureCA\n",
    "from Bio.Data.PDBData import protein_letters_3to1\n",
    "from pdbfixer import PDBFixer\n",
    "from openmm.app import PDBFile\n",
    "\n",
    "# Constants\n",
    "HYDRO = {\n",
    "    'A': 1.8, 'R': -4.5, 'N': -3.5, 'D': -3.5, 'C': 2.5,\n",
    "    'Q': -3.5, 'E': -3.5, 'G': -0.4, 'H': -3.2, 'I': 4.5,\n",
    "    'L': 3.8, 'K': -3.9, 'M': 1.9, 'F': 2.8, 'P': -1.6,\n",
    "    'S': -0.8, 'T': -0.7, 'W': -0.9, 'Y': -1.3, 'V': 4.2\n",
    "}\n",
    "\n",
    "MAX_ASA = {\n",
    "    'A': 121, 'R': 265, 'N': 187, 'D': 187, 'C': 148, 'Q': 214, 'E': 223,\n",
    "    'G': 97,  'H': 216, 'I': 195, 'L': 191, 'K': 230, 'M': 203, 'F': 228,\n",
    "    'P': 154, 'S': 143, 'T': 163, 'W': 264, 'Y': 255, 'V': 165\n",
    "}\n",
    "\n",
    "VDW_RADII = {'H': 1.2, 'C': 1.7, 'N': 1.55, 'O': 1.52, 'S': 1.8}\n",
    "\n",
    "def resname_to_one(resname): return protein_letters_3to1.get(resname.upper(), 'X')\n",
    "\n",
    "def fix_and_load_structure(pdb_path):\n",
    "    fixer = PDBFixer(filename=pdb_path)\n",
    "    fixer.findMissingResidues()\n",
    "    fixer.findMissingAtoms()\n",
    "    fixer.addMissingAtoms()\n",
    "    fixer.addMissingHydrogens(pH=7.4)\n",
    "    fixed_path = \"fixed_structure.pdb\"\n",
    "    with open(fixed_path, \"w\") as f:\n",
    "        PDBFile.writeFile(fixer.topology, fixer.positions, f)\n",
    "    traj = md.load(fixed_path)\n",
    "    structure = PDBParser(QUIET=True).get_structure(\"X\", fixed_path)\n",
    "    return traj, structure\n",
    "\n",
    "def compute_sasa(traj, structure):\n",
    "    sasa_nm2 = md.shrake_rupley(traj, probe_radius=0.14, mode='residue')\n",
    "    sasa = sasa_nm2[0] * 100.0\n",
    "    residues = list(structure.get_residues())\n",
    "    norm = [sasa[i] / MAX_ASA.get(resname_to_one(r.get_resname()), np.nan) for i, r in enumerate(residues)]\n",
    "    return sasa, np.array(norm)\n",
    "\n",
    "def compute_torsions(traj, structure):\n",
    "    torsion_types = [md.compute_phi, md.compute_psi, md.compute_omega, md.compute_chi1]\n",
    "    torsion_data = {}\n",
    "    for func in torsion_types:\n",
    "        idx, vals = func(traj)\n",
    "        for i, val in zip(idx[:,1], vals[0]):\n",
    "            torsion_data.setdefault(i, []).append(val)\n",
    "    residues = list(structure.get_residues())\n",
    "    results = [[*torsion_data.get(i, [np.nan]*4)] for i in range(len(residues))]\n",
    "    return np.array(results).T\n",
    "\n",
    "def compute_hbonds(traj):\n",
    "    hb = md.baker_hubbard(traj, periodic=False)\n",
    "    counts = {}\n",
    "    for i, j, k in hb:\n",
    "        for atom in (i, k):\n",
    "            res = traj.topology.atom(atom).residue.index\n",
    "            counts[res] = counts.get(res, 0) + 1\n",
    "    return counts\n",
    "\n",
    "def compute_salt_bridges(traj):\n",
    "    acidic = [\"ASP\", \"GLU\"]\n",
    "    basic = [\"ARG\", \"LYS\", \"HIS\"]\n",
    "    atoms = traj.topology.atoms\n",
    "    pairs = [(i, j) for i in range(len(atoms)) for j in range(i+1, len(atoms))\n",
    "             if atoms[i].residue.name in acidic and atoms[j].residue.name in basic]\n",
    "    if not pairs: return {}\n",
    "    dists = md.compute_distances(traj, pairs)[0]\n",
    "    sb_counts = {}\n",
    "    for (i, j), dist in zip(pairs, dists):\n",
    "        if dist < 0.4:\n",
    "            for idx in (i, j):\n",
    "                res = traj.topology.atom(idx).residue.index\n",
    "                sb_counts[res] = sb_counts.get(res, 0) + 1\n",
    "    return sb_counts\n",
    "\n",
    "def compute_disulfides(traj):\n",
    "    sg = traj.topology.select(\"resname CYS and name SG\")\n",
    "    if len(sg) < 2: return {}\n",
    "    pairs = [(i, j) for i in sg for j in sg if i < j]\n",
    "    dists = md.compute_distances(traj, pairs)[0]\n",
    "    bonded = {traj.topology.atom(sg[i]).residue.index for idx, (i, j) in enumerate(pairs) if 0 < dists[idx] < 0.22}\n",
    "    return {idx: 1 for idx in bonded}\n",
    "\n",
    "def compute_pi_pi(traj, structure):\n",
    "    aromatics = {\"PHE\", \"TYR\", \"TRP\"}\n",
    "    centers = {}\n",
    "    for chain in structure[0]:\n",
    "        for res in chain:\n",
    "            if res.get_resname() in aromatics:\n",
    "                coords = np.array([a.get_vector().get_array() for a in res if a.element != 'H'])\n",
    "                centers[res.id[1]] = coords.mean(axis=0) if len(coords) > 0 else None\n",
    "    counts = {k: 0 for k in centers}\n",
    "    keys = list(centers)\n",
    "    for i in range(len(keys)):\n",
    "        for j in range(i+1, len(keys)):\n",
    "            if np.linalg.norm(centers[keys[i]] - centers[keys[j]]) < 7.0:\n",
    "                counts[keys[i]] += 1\n",
    "                counts[keys[j]] += 1\n",
    "    return counts\n",
    "\n",
    "def compute_vdw_contacts(traj):\n",
    "    coords = traj.xyz[0] * 10\n",
    "    elems = [a.element.symbol for a in traj.topology.atoms]\n",
    "    radii = np.array([VDW_RADII.get(e, 1.5) for e in elems])\n",
    "    resmap = {a.index: a.residue.index for a in traj.topology.atoms}\n",
    "    contacts = {i: set() for i in set(resmap.values())}\n",
    "    for i in range(len(coords)):\n",
    "        for j in range(i+1, len(coords)):\n",
    "            if resmap[i] == resmap[j]: continue\n",
    "            if np.linalg.norm(coords[i] - coords[j]) < (radii[i] + radii[j] + 0.05):\n",
    "                contacts[resmap[i]].add(resmap[j])\n",
    "                contacts[resmap[j]].add(resmap[i])\n",
    "    return {k: len(v) for k, v in contacts.items()}\n",
    "\n",
    "def compute_packing_density(traj):\n",
    "    ca = traj.topology.select(\"name CA\")\n",
    "    coords = traj.xyz[0][ca] * 10\n",
    "    vol = 4 / 3 * np.pi * 1.0**3 * 1e3\n",
    "    densities = np.zeros(len(traj.topology.residues))\n",
    "    for i, res in enumerate(ca):\n",
    "        d = np.linalg.norm(coords - coords[i], axis=1)\n",
    "        densities[i] = (np.sum(d < 10) - 1) / vol\n",
    "    return densities\n",
    "\n",
    "def compute_depth_protrusion(structure):\n",
    "    atoms = np.array([a.get_vector().get_array() for a in structure.get_atoms()])\n",
    "    com = atoms.mean(axis=0)\n",
    "    depths, protr = [], []\n",
    "    for res in structure.get_residues():\n",
    "        coords = np.array([a.get_vector().get_array() for a in res if a.element != 'H'])\n",
    "        d = np.linalg.norm(coords - com, axis=1)\n",
    "        depths.append(d.mean())\n",
    "        protr.append(d.max() - d.mean())\n",
    "    return np.array(depths), np.array(protr)\n",
    "\n",
    "def compute_half_sphere_exposure(structure):\n",
    "    hse = HSExposureCA(structure[0])\n",
    "    up, down = [], []\n",
    "    for res in structure.get_residues():\n",
    "        try:\n",
    "            u, d = hse[(res, 'CA')]\n",
    "            up.append(u)\n",
    "            down.append(d)\n",
    "        except:\n",
    "            up.append(np.nan); down.append(np.nan)\n",
    "    return np.array(up), np.array(down)\n",
    "\n",
    "def compute_secondary_structure(traj):\n",
    "    ss = traj.secondary_structure()[0]\n",
    "    total = len(ss)\n",
    "    content = {k: round((ss == k).sum() / total, 3) for k in 'HEC'}\n",
    "    return content\n",
    "\n",
    "def compute_contact_order(traj):\n",
    "    ca = traj.topology.select(\"name CA\")\n",
    "    if len(ca) < 2: return 0\n",
    "    pairs = np.array([[i, j] for i in ca for j in ca if abs(i - j) >= 3])\n",
    "    dists = md.compute_distances(traj, pairs)[0]\n",
    "    contact_pairs = pairs[dists < 0.8]\n",
    "    sum_seq_sep = np.sum(np.abs(contact_pairs[:, 0] - contact_pairs[:, 1]))\n",
    "    return round(sum_seq_sep / (len(contact_pairs) * len(ca)), 3) if len(contact_pairs) else 0\n",
    "\n",
    "def analyze(pdb_path):\n",
    "    traj, struct = fix_and_load_structure(pdb_path)\n",
    "    residues = list(struct.get_residues())\n",
    "    sasa, sasa_norm = compute_sasa(traj, struct)\n",
    "    phi, psi, omega, chi1 = compute_torsions(traj, struct)\n",
    "    hb = compute_hbonds(traj)\n",
    "    sb = compute_salt_bridges(traj)\n",
    "    ss = compute_disulfides(traj)\n",
    "    pi = compute_pi_pi(traj, struct)\n",
    "    vdw = compute_vdw_contacts(traj)\n",
    "    pdens = compute_packing_density(traj)\n",
    "    depth, protr = compute_depth_protrusion(struct)\n",
    "    hsu, hsd = compute_half_sphere_exposure(struct)\n",
    "\n",
    "    data = []\n",
    "    for i, res in enumerate(residues):\n",
    "        aa1 = resname_to_one(res.get_resname())\n",
    "        data.append({\n",
    "            \"chain\": res.get_parent().id,\n",
    "            \"resSeq\": res.id[1],\n",
    "            \"resName\": aa1,\n",
    "            \"ASA\": sasa[i],\n",
    "            \"ASA_norm\": sasa_norm[i],\n",
    "            \"phi\": phi[i],\n",
    "            \"psi\": psi[i],\n",
    "            \"omega\": omega[i],\n",
    "            \"chi1\": chi1[i],\n",
    "            \"Hbond_count\": hb.get(i, 0),\n",
    "            \"salt_bridge_count\": sb.get(i, 0),\n",
    "            \"ss_bridge\": ss.get(i, 0),\n",
    "            \"pi_pi_count\": pi.get(i, 0),\n",
    "            \"vdw_partners\": vdw.get(i, 0),\n",
    "            \"packing_density\": pdens[i],\n",
    "            \"depth\": depth[i],\n",
    "            \"protrusion\": protr[i],\n",
    "            \"hydrophobicity\": HYDRO.get(aa1, np.nan),\n",
    "            \"HSE_up\": hsu[i],\n",
    "            \"HSE_down\": hsd[i]\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "    df.to_csv(\"per_residue_descriptors.csv\", index=False)\n",
    "\n",
    "    # Global descriptors\n",
    "    ss_content = compute_secondary_structure(traj)\n",
    "    contact_order = compute_contact_order(traj)\n",
    "    global_desc = {\n",
    "        \"Total_SASA\": round(sasa.sum(), 2),\n",
    "        \"Alpha_helix_content\": ss_content.get('H', 0.0),\n",
    "        \"Beta_strand_content\": ss_content.get('E', 0.0),\n",
    "        \"Coil_content\": ss_content.get('C', 0.0),\n",
    "        \"Contact_order\": contact_order,\n",
    "        \"Total_Hbonds\": sum(hb.values()),\n",
    "        \"Total_salt_bridges\": sum(sb.values()),\n",
    "        \"Total_ss_bridges\": sum(ss.values()) // 2,\n",
    "        \"Total_pi_pi\": sum(pi.values()) // 2\n",
    "    }\n",
    "    pd.Series(global_desc).to_csv(\"global_descriptors.csv\")\n",
    "    print(\"→ Saved per_residue_descriptors.csv and global_descriptors.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if len(sys.argv) == 2:\n",
    "        analyze(sys.argv[1])\n",
    "    else:\n",
    "        print(\"Usage: python analyze_protein.py <structure.pdb>\")"
   ],
   "metadata": {
    "id": "tI6S06JaGkxB"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}