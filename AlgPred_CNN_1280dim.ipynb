{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeffateth/AllergenPredict/blob/main/AlgPred_CNN_1280dim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeR7saFIL_2d",
        "outputId": "8ca829b7-db5a-410a-d5ff-46d1ed1d8136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Mounted at /content/drive\n",
            "All generated files will be saved to: /content/drive/MyDrive/AllergenAI new/CNN\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas requests\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Drive. (Authorize when prompted.)\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the folder where you'll save your outputs.\n",
        "drive_path = \"/content/drive/MyDrive/AllergenAI new/CNN\"\n",
        "\n",
        "\n",
        "print(f\"All generated files will be saved to: {drive_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilcsg8tr0Nus",
        "outputId": "2a95e490-c578-4635-fda6-866c2db9c8a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Output folder: /content/drive/MyDrive/AllergenAI_new\n",
            "⬇️ Downloading train_positive\n",
            "⬇️ Downloading train_negative\n",
            "✅ Saved train set: 16120 entries\n",
            "Saved files in: /content/drive/MyDrive/AllergenAI_new\n",
            "⬇️ Downloading test_positive\n",
            "⬇️ Downloading test_negative\n",
            "✅ Saved test set: 4030 entries\n",
            "Saved files in: /content/drive/MyDrive/AllergenAI_new\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import os\n",
        "\n",
        "# -------------------------------\n",
        "# Mount Google Drive\n",
        "# -------------------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the folder path on your Drive (adjust as needed)\n",
        "drive_path = \"/content/drive/MyDrive/AllergenAI new/CNN\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "print(\"Output folder:\", drive_path)\n",
        "\n",
        "# -------------------------------\n",
        "# URLs and Fasta Parser\n",
        "# -------------------------------\n",
        "datasets = {\n",
        "    \"train_positive\": (\"https://webs.iiitd.edu.in/raghava/algpred2/datasets/train_positive.txt\", 1),\n",
        "    \"train_negative\": (\"https://webs.iiitd.edu.in/raghava/algpred2/datasets/train_negative.txt\", 0),\n",
        "    \"test_positive\": (\"https://webs.iiitd.edu.in/raghava/algpred2/datasets/validation_positive.txt\", 1),\n",
        "    \"test_negative\": (\"https://webs.iiitd.edu.in/raghava/algpred2/datasets/validation_negative.txt\", 0)\n",
        "}\n",
        "\n",
        "def parse_fasta(text, label):\n",
        "    entries, cur_id, cur_seq = [], None, \"\"\n",
        "    for line in text.strip().splitlines():\n",
        "        line = line.strip()\n",
        "        if line.startswith(\">\"):\n",
        "            if cur_id:\n",
        "                entries.append((cur_id, cur_seq, label))\n",
        "            cur_id = line[1:]\n",
        "            cur_seq = \"\"\n",
        "        else:\n",
        "            cur_seq += line\n",
        "    if cur_id and cur_seq:\n",
        "        entries.append((cur_id, cur_seq, label))\n",
        "    return entries\n",
        "\n",
        "# -------------------------------\n",
        "# Process and Save Each Dataset\n",
        "# -------------------------------\n",
        "for setname in [\"train\", \"test\"]:\n",
        "    entries = []\n",
        "    for k, (url, label) in datasets.items():\n",
        "        if k.startswith(setname):\n",
        "            print(f\"⬇️ Downloading {k}\")\n",
        "            r = requests.get(url)\n",
        "            entries.extend(parse_fasta(r.text, label))\n",
        "    df = pd.DataFrame(entries, columns=[\"id\", \"sequence\", \"label\"])\n",
        "\n",
        "    # Save to Google Drive folder using os.path.join to form a full path\n",
        "    out_csv = os.path.join(drive_path, f\"algpred2_{setname}.csv\")\n",
        "    df.to_csv(out_csv, index=False)\n",
        "\n",
        "    print(f\"✅ Saved {setname} set: {len(df)} entries\")\n",
        "    print(\"Saved files in:\", drive_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GWihiZlc0iLM",
        "outputId": "2591237b-803f-4bc4-beb9-1a236bbe6d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fair-esm\n",
            "  Downloading fair_esm-2.0.0-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading fair_esm-2.0.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fair-esm, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed fair-esm-2.0.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ],
      "source": [
        "!pip install fair-esm torch pandas tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1_Jv62ty0mrA",
        "outputId": "ea84c053-7604-4e25-d3b3-fb6739f9405d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/models/esm2_t33_650M_UR50D.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D.pt\n",
            "Downloading: \"https://dl.fbaipublicfiles.com/fair-esm/regression/esm2_t33_650M_UR50D-contact-regression.pt\" to /root/.cache/torch/hub/checkpoints/esm2_t33_650M_UR50D-contact-regression.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚙️  Extracting embeddings using ESM-2 for algpred2_test.csv... (4030 sequences remaining)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4030/4030 [05:14<00:00, 12.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Final embeddings saved to 'algpred2_test_esm2_embeddings.csv'\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import esm\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import csv\n",
        "\n",
        "#for dataset in [\"algpred2_train.csv\", \"algpred2_test.csv\"]:\n",
        "for dataset in [\"algpred2_test.csv\"]:\n",
        "    # Determine base name\n",
        "    base = os.path.splitext(os.path.basename(dataset))[0]\n",
        "\n",
        "    # Load dataset\n",
        "    df = pd.read_csv(dataset)\n",
        "    sequences = list(df[\"sequence\"])\n",
        "    labels = list(df[\"label\"])\n",
        "    ids = list(df[\"id\"])\n",
        "\n",
        "    # Load ESM-2 model\n",
        "    model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
        "    batch_converter = alphabet.get_batch_converter()\n",
        "    model.eval()\n",
        "\n",
        "    # Device\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model = model.to(device)\n",
        "\n",
        "    # Output files (unique per dataset)\n",
        "    temp_file = f\"{base}_esm2_embeddings_temp.csv\"\n",
        "    final_file = f\"{base}_esm2_embeddings.csv\"\n",
        "\n",
        "    # Already processed IDs (for resuming)\n",
        "    if os.path.exists(temp_file):\n",
        "        processed_ids = set(pd.read_csv(temp_file, usecols=[\"id\"])[\"id\"])\n",
        "        print(f\"🔁 Resuming from {temp_file} — {len(processed_ids)} entries already processed.\")\n",
        "    else:\n",
        "        processed_ids = set()\n",
        "\n",
        "    # Filter data\n",
        "    remaining_data = [(ids[i], sequences[i], labels[i]) for i in range(len(ids)) if ids[i] not in processed_ids]\n",
        "\n",
        "    # Batch setup\n",
        "    batch_size = 1\n",
        "    write_header = not os.path.exists(temp_file)\n",
        "    feature_dim = 1280\n",
        "    fieldnames = [\"id\", \"label\"] + [f\"f{k}\" for k in range(feature_dim)]\n",
        "\n",
        "    print(f\"⚙️  Extracting embeddings using ESM-2 for {dataset}... ({len(remaining_data)} sequences remaining)\")\n",
        "\n",
        "    with open(temp_file, mode=\"a\", newline=\"\") as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
        "        if write_header:\n",
        "            writer.writeheader()\n",
        "\n",
        "        for i in tqdm(range(0, len(remaining_data), batch_size)):\n",
        "            batch = remaining_data[i:i + batch_size]\n",
        "            batch_ids = [x[0] for x in batch]\n",
        "            batch_seqs = [x[1] for x in batch]\n",
        "            batch_labels = [x[2] for x in batch]\n",
        "\n",
        "            batch_data = [(batch_ids[j], batch_seqs[j]) for j in range(len(batch_seqs))]\n",
        "            _, _, batch_tokens = batch_converter(batch_data)\n",
        "            batch_tokens = batch_tokens.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(batch_tokens, repr_layers=[33])  # Layer 33 for T33\n",
        "                token_representations = outputs[\"representations\"][33]\n",
        "\n",
        "            rows = []\n",
        "            for j, (_, seq) in enumerate(batch_data):\n",
        "                representation = token_representations[j, 1:len(seq)+1].mean(0)\n",
        "                entry = {\n",
        "                    \"id\": batch_ids[j],\n",
        "                    \"label\": batch_labels[j],\n",
        "                }\n",
        "                for k in range(feature_dim):\n",
        "                    entry[f\"f{k}\"] = representation[k].item()\n",
        "                rows.append(entry)\n",
        "\n",
        "            writer.writerows(rows)\n",
        "\n",
        "    # Final save\n",
        "    os.replace(temp_file, final_file)\n",
        "\n",
        "    print(f\"✅ Final embeddings saved to '{final_file}'\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bbgdtsm87X__",
        "outputId": "b4270396-a363-4706-a737-987c55eb4120"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     id                                           sequence  label\n",
            "0  P_13  MGKPFTLSLSSLCLLLLSSACFAISSSKLNECQLNNLNALEPDHRV...      1\n",
            "1  P_14  MGVFTFEDEINSPVAPATLYKALVTDADNVIPKALDSFKSVENVEG...      1\n",
            "2  P_17  MAEDEDNQQGQGEGLKYLGFVQDAATYAVTTFSNVYLFAKDKSGPL...      1\n",
            "3  P_46  MGVFNYEVETPSVISAARLFKSYVLDGDKLIPKVAPQAITSVENVG...      1\n",
            "4  P_47  MGVFNYEVETPSVIPAARLFKSYVLDGDKLIPKVAPQAITSVENVE...      1\n",
            "(16120, 3)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"algpred2_train.csv\")\n",
        "print(df.head())\n",
        "print(df.shape)  # Rows, features"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN\n"
      ],
      "metadata": {
        "id": "Os8kRJZdkp1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner --upgrade --quiet\n",
        "\n"
      ],
      "metadata": {
        "id": "Ohvm21yLRc4B",
        "outputId": "28571bfd-40cb-46df-b6d7-1f7e58a48f43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v1qxkMygeYDt",
        "outputId": "46bda0f5-e768-4e81-ff0f-6fe0a472be18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 23s]\n",
            "val_accuracy: 0.628722071647644\n",
            "\n",
            "Best val_accuracy So Far: 0.7099875807762146\n",
            "Total elapsed time: 00h 05m 15s\n",
            "\n",
            "Best hyperparameters found:\n",
            " - Filters: 16\n",
            " - Kernel Size: 5\n",
            " - Dropout Rate: 0.2\n",
            " - Dense Units: 64\n",
            " - Learning Rate: 0.0036569295366168696\n",
            "\n",
            "Training final model...\n",
            "Epoch 1/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.6260 - loss: 0.6636 - val_accuracy: 0.1678 - val_loss: 1.1206\n",
            "Epoch 2/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.6730 - loss: 0.6019 - val_accuracy: 0.7602 - val_loss: 0.5504\n",
            "Epoch 3/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7044 - loss: 0.5477 - val_accuracy: 0.4907 - val_loss: 0.7543\n",
            "Epoch 4/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7267 - loss: 0.5307 - val_accuracy: 0.8189 - val_loss: 0.5329\n",
            "Epoch 5/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7268 - loss: 0.5217 - val_accuracy: 0.8524 - val_loss: 0.4700\n",
            "Epoch 6/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7381 - loss: 0.5042 - val_accuracy: 0.8285 - val_loss: 0.4959\n",
            "Epoch 7/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7452 - loss: 0.4945 - val_accuracy: 0.8452 - val_loss: 0.4466\n",
            "Epoch 8/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7525 - loss: 0.4878 - val_accuracy: 0.7919 - val_loss: 0.5272\n",
            "Epoch 9/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7631 - loss: 0.4851 - val_accuracy: 0.5872 - val_loss: 0.7038\n",
            "Epoch 10/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.7580 - loss: 0.4805 - val_accuracy: 0.8396 - val_loss: 0.4528\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\n",
            "Final Evaluation on Test Set:\n",
            "Final Test ROC-AUC: 0.7453\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.6115    0.8367    0.7066      2015\n",
            "           1     0.7416    0.4685    0.5742      2015\n",
            "\n",
            "    accuracy                         0.6526      4030\n",
            "   macro avg     0.6765    0.6526    0.6404      4030\n",
            "weighted avg     0.6765    0.6526    0.6404      4030\n",
            "\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "Y-Scrambled AUC: 0.4976 ± 0.0016\n",
            "\n",
            "✅ Logs saved to: /content/drive/MyDrive/AllergenAI-new/CNN/evaluation_log_cpu.txt\n"
          ]
        }
      ],
      "source": [
        "# ===============================\n",
        "# Step 0: Imports\n",
        "# ===============================\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "# TensorFlow / Keras\n",
        "import tensorflow as tf\n",
        "import keras_tuner as kt\n",
        "\n",
        "# XGBoost (for Y-Scrambling)\n",
        "import xgboost as xgb\n",
        "\n",
        "# Output redirection\n",
        "import sys\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 1: Mount Google Drive\n",
        "# ===============================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_path = \"/content/drive/MyDrive/AllergenAI-new/CNN\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "print(f\"All generated files will be saved to: {drive_path}\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 2: Load and Prepare Data\n",
        "# ===============================\n",
        "df_train = pd.read_csv(\"/content/drive/MyDrive/AllergenAI-new/CNN/algpred2_train_esm2_1280dim_embeddings.csv\")\n",
        "df_test = pd.read_csv(\"/content/drive/MyDrive/AllergenAI-new/CNN/algpred2_test_esm2_1280dim_embeddings.csv\")\n",
        "\n",
        "\n",
        "feature_cols = [f\"f{i}\" for i in range(1280)]\n",
        "X_train = df_train[feature_cols].values\n",
        "y_train = df_train[\"label\"].values\n",
        "X_test = df_test[feature_cols].values\n",
        "y_test = df_test[\"label\"].values\n",
        "\n",
        "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n",
        "X_temp, y_temp = X_train, y_train\n",
        "\n",
        "\n",
        "# ====================================\n",
        "# Step 3: Dummy Classifier Baseline\n",
        "# ====================================\n",
        "print(\"\\n📉 DummyClassifier (Stratified) on Train+Val:\\n\")\n",
        "dummy = DummyClassifier(strategy=\"stratified\", random_state=42)\n",
        "dummy_aucs = []\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for train_idx, val_idx in cv.split(X_temp, y_temp):\n",
        "    dummy.fit(X_temp[train_idx], y_temp[train_idx])\n",
        "    y_dummy_proba = dummy.predict_proba(X_temp[val_idx])[:, 1]\n",
        "    auc = roc_auc_score(y_temp[val_idx], y_dummy_proba)\n",
        "    dummy_aucs.append(auc)\n",
        "print(f\"📊 Dummy ROC-AUC: {np.mean(dummy_aucs):.4f} ± {np.std(dummy_aucs):.4f}\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 4: Reshape for CNN\n",
        "# ===============================\n",
        "X_train = X_train.reshape(-1, 1280, 1)\n",
        "X_test = X_test.reshape(-1, 1280, 1)\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 5: Define Hypermodel\n",
        "# ===============================\n",
        "def build_cnn_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.Input(shape=(1280, 1)))\n",
        "    model.add(tf.keras.layers.Conv1D(\n",
        "        filters=hp.Choice('filters', values=[16, 32, 64]),\n",
        "        kernel_size=hp.Choice('kernel_size', values=[3, 5]),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
        "    model.add(tf.keras.layers.Dropout(rate=hp.Float('dropout', 0.2, 0.5, step=0.1)))\n",
        "    model.add(tf.keras.layers.Dense(\n",
        "        units=hp.Int('dense_units', min_value=16, max_value=64, step=16),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(hp.Float('lr', 1e-4, 1e-2, sampling='LOG')),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 6: Hyperparameter Tuning\n",
        "# ===============================\n",
        "X_train_part, X_val, y_train_part, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, train_size=0.1, stratify=y_train, random_state=42\n",
        ")\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_cnn_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='cnn_tuning_cpu',\n",
        "    project_name='AllergenPredict_CNN_CPU'\n",
        ")\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "class ClearMemoryCallback(tf.keras.callbacks.Callback):\n",
        "    def on_train_end(self, logs=None):\n",
        "        tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "\n",
        "print(\"\\n🚀 Starting hyperparameter tuning...\")\n",
        "tuner.search(\n",
        "    X_train_part, y_train_part,\n",
        "    epochs=5,\n",
        "    batch_size=8,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[stop_early, ClearMemoryCallback()]\n",
        ")\n",
        "gc.collect()\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"\\nBest hyperparameters found:\")\n",
        "print(f\" - Filters: {best_hps.get('filters')}\")\n",
        "print(f\" - Kernel Size: {best_hps.get('kernel_size')}\")\n",
        "print(f\" - Dropout Rate: {best_hps.get('dropout')}\")\n",
        "print(f\" - Dense Units: {best_hps.get('dense_units')}\")\n",
        "print(f\" - Learning Rate: {best_hps.get('lr')}\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 7: Final Model Training\n",
        "# ===============================\n",
        "print(\"\\nTraining final model...\")\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    validation_split=0.2,\n",
        "    batch_size=8,\n",
        "    callbacks=[stop_early]\n",
        ")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 8: Evaluate on Test Set\n",
        "# ===============================\n",
        "y_test_proba = model.predict(X_test).ravel()\n",
        "y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
        "\n",
        "test_auc = roc_auc_score(y_test, y_test_proba)\n",
        "report = classification_report(y_test, y_test_pred, digits=4)\n",
        "\n",
        "print(\"\\nFinal Evaluation on Test Set:\")\n",
        "print(f\"Final Test ROC-AUC: {test_auc:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 9: Y-Scrambling Control\n",
        "# ===============================\n",
        "y_scrambled = y_train.copy()\n",
        "random.seed(42)\n",
        "random.shuffle(y_scrambled)\n",
        "\n",
        "scrambled_aucs = []\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for train_idx, val_idx in cv.split(X_train, y_scrambled):\n",
        "    X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
        "    y_fold_train, y_fold_val = y_scrambled[train_idx], y_scrambled[val_idx]\n",
        "\n",
        "    model_scrambled = tf.keras.Sequential([\n",
        "        tf.keras.Input(shape=(1280, 1)),\n",
        "        tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
        "        tf.keras.layers.GlobalMaxPooling1D(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model_scrambled.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    model_scrambled.fit(X_fold_train, y_fold_train, epochs=5, verbose=0)\n",
        "    y_proba_scrambled = model_scrambled.predict(X_fold_val).ravel()\n",
        "    auc = roc_auc_score(y_fold_val, y_proba_scrambled)\n",
        "    scrambled_aucs.append(auc)\n",
        "\n",
        "print(f\"Y-Scrambled AUC: {np.mean(scrambled_aucs):.4f} ± {np.std(scrambled_aucs):.4f}\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 10: Save Log to Drive\n",
        "# ===============================\n",
        "log_filepath = os.path.join(drive_path, \"evaluation_log_cpu.txt\")\n",
        "with open(log_filepath, \"w\") as f_out, redirect_stdout(f_out):\n",
        "    print(\"Final Evaluation on Test Set:\")\n",
        "    print(f\"Final Test ROC-AUC: {test_auc:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "print(f\"\\n✅ Logs saved to: {log_filepath}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MLP - Multi-Layer Perceptron"
      ],
      "metadata": {
        "id": "q3trvf0coRZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# Step 4: Use flat features (no reshape)\n",
        "# ===============================\n",
        "# No need to reshape: X_train and X_test already have shape (n_samples, 1280)\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 5: Define the MLP Model\n",
        "# ===============================\n",
        "def build_mlp_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.Input(shape=(1280,)))\n",
        "\n",
        "    # 1 to 3 hidden layers\n",
        "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
        "        model.add(tf.keras.layers.Dense(\n",
        "            units=hp.Int(f\"units_{i}\", min_value=64, max_value=256, step=64),\n",
        "            activation='relu'\n",
        "        ))\n",
        "        model.add(tf.keras.layers.Dropout(\n",
        "            rate=hp.Float(f\"dropout_{i}\", min_value=0.2, max_value=0.5, step=0.1)\n",
        "        ))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            hp.Float(\"lr\", 1e-4, 1e-2, sampling='log')\n",
        "        ),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 6: Hyperparameter Tuning\n",
        "# ===============================\n",
        "X_train_part, X_val, y_train_part, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, train_size=0.1, stratify=y_train, random_state=42\n",
        ")\n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "    build_mlp_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='mlp_tuning',\n",
        "    project_name='AllergenPredict_MLP'\n",
        ")\n",
        "\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "class ClearMemoryCallback(tf.keras.callbacks.Callback):\n",
        "    def on_train_end(self, logs=None):\n",
        "        tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "\n",
        "print(\"\\n🚀 Starting MLP hyperparameter tuning...\")\n",
        "tuner.search(\n",
        "    X_train_part, y_train_part,\n",
        "    epochs=5,\n",
        "    batch_size=8,\n",
        "    validation_data=(X_val, y_val),\n",
        "    callbacks=[stop_early, ClearMemoryCallback()]\n",
        ")\n",
        "gc.collect()\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"\\nBest hyperparameters found for MLP:\")\n",
        "print(f\" - Layers: {best_hps.get('num_layers')}\")\n",
        "for i in range(best_hps.get('num_layers')):\n",
        "    print(f\"   - Layer {i+1}: {best_hps.get(f'units_{i}')} units, dropout {best_hps.get(f'dropout_{i}')}\")\n",
        "print(f\" - Learning Rate: {best_hps.get('lr')}\")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 7: Final Model Training\n",
        "# ===============================\n",
        "print(\"\\nTraining final MLP model...\")\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    validation_split=0.2,\n",
        "    batch_size=8,\n",
        "    callbacks=[stop_early]\n",
        ")\n",
        "\n",
        "\n",
        "# ===============================\n",
        "# Step 8: Evaluate on Test Set\n",
        "# ===============================\n",
        "y_test_proba = model.predict(X_test).ravel()\n",
        "y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
        "\n",
        "test_auc = roc_auc_score(y_test, y_test_proba)\n",
        "report = classification_report(y_test, y_test_pred, digits=4)\n",
        "\n",
        "print(\"\\nFinal Evaluation on Test Set (MLP):\")\n",
        "print(f\"Final Test ROC-AUC: {test_auc:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n"
      ],
      "metadata": {
        "id": "1-domUL9oXPq",
        "outputId": "ad54ab2f-3c9b-45da-d075-584e00445a7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 00m 22s]\n",
            "val_accuracy: 0.9640198349952698\n",
            "\n",
            "Best val_accuracy So Far: 0.9652605652809143\n",
            "Total elapsed time: 00h 04m 53s\n",
            "\n",
            "Best hyperparameters found for MLP:\n",
            " - Layers: 2\n",
            "   - Layer 1: 192 units, dropout 0.2\n",
            "   - Layer 2: 64 units, dropout 0.2\n",
            " - Learning Rate: 0.0004231890726974646\n",
            "\n",
            "Training final MLP model...\n",
            "Epoch 1/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.9173 - loss: 0.2089 - val_accuracy: 0.9274 - val_loss: 0.2200\n",
            "Epoch 2/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9664 - loss: 0.0997 - val_accuracy: 0.9625 - val_loss: 0.1232\n",
            "Epoch 3/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9751 - loss: 0.0785 - val_accuracy: 0.9774 - val_loss: 0.0701\n",
            "Epoch 4/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.0653 - val_accuracy: 0.9380 - val_loss: 0.1816\n",
            "Epoch 5/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9855 - loss: 0.0492 - val_accuracy: 0.9730 - val_loss: 0.0933\n",
            "Epoch 6/20\n",
            "\u001b[1m1612/1612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.0429 - val_accuracy: 0.9637 - val_loss: 0.1294\n",
            "\u001b[1m126/126\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\n",
            "Final Evaluation on Test Set (MLP):\n",
            "Final Test ROC-AUC: 0.9718\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8869    0.9687    0.9260      2015\n",
            "           1     0.9656    0.8764    0.9188      2015\n",
            "\n",
            "    accuracy                         0.9226      4030\n",
            "   macro avg     0.9262    0.9226    0.9224      4030\n",
            "weighted avg     0.9262    0.9226    0.9224      4030\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Install dependencies\n",
        "!pip install -q tensorflow scikeras\n",
        "\n",
        "# ==============================\n",
        "# ✅ Imports and Setup\n",
        "# ==============================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ==============================\n",
        "# ✅ Load ESM-2 Embedding Data\n",
        "# ==============================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "train_csv = \"/content/drive/MyDrive/AllergenAI-new/CNN/algpred2_train_esm2_1280dim_embeddings.csv\"\n",
        "df = pd.read_csv(train_csv)\n",
        "\n",
        "feature_cols = [f\"f{i}\" for i in range(1280)]\n",
        "X = df[feature_cols].values\n",
        "y = df[\"label\"].values\n",
        "\n",
        "# ==============================\n",
        "# ✅ Define the MLP model (TF/Keras)\n",
        "# ==============================\n",
        "def create_mlp_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(192, activation='relu', input_shape=(1280,)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0004),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "mlp_clf = KerasClassifier(model=create_mlp_model, epochs=10, batch_size=32, verbose=0)\n",
        "\n",
        "mlp_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('mlp', mlp_clf)\n",
        "])\n",
        "\n",
        "xgb_clf = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "\n",
        "# ==============================\n",
        "# ✅ Nested Cross-Validation (5-fold)\n",
        "# ==============================\n",
        "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "outer_accuracies = []\n",
        "outer_aucs = []\n",
        "\n",
        "for fold, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n",
        "    print(f\"\\n🚀 Fold {fold}/5\")\n",
        "\n",
        "    X_train, X_test = X[train_idx], X[test_idx]\n",
        "    y_train, y_test = y[train_idx], y[test_idx]\n",
        "\n",
        "    # Train models\n",
        "    mlp_pipeline.fit(X_train, y_train)\n",
        "    xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "    # --- MLP ---\n",
        "    X_test_scaled = mlp_pipeline.named_steps['scaler'].transform(X_test)\n",
        "    y_proba_mlp = mlp_pipeline.named_steps['mlp'].predict_proba(X_test_scaled)[:, 1]\n",
        "    y_pred_mlp = (y_proba_mlp >= 0.5).astype(int)\n",
        "    acc_mlp = accuracy_score(y_test, y_pred_mlp)\n",
        "    auc_mlp = roc_auc_score(y_test, y_proba_mlp)\n",
        "\n",
        "    # --- XGBoost ---\n",
        "    y_proba_xgb = xgb_clf.predict_proba(X_test)[:, 1]\n",
        "    y_pred_xgb = (y_proba_xgb >= 0.5).astype(int)\n",
        "    acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
        "    auc_xgb = roc_auc_score(y_test, y_proba_xgb)\n",
        "\n",
        "    # --- Ensemble (Soft Voting) ---\n",
        "    y_proba_ens = 0.5 * y_proba_mlp + 0.5 * y_proba_xgb\n",
        "    y_pred_ens = (y_proba_ens >= 0.5).astype(int)\n",
        "    acc_ens = accuracy_score(y_test, y_pred_ens)\n",
        "    auc_ens = roc_auc_score(y_test, y_proba_ens)\n",
        "\n",
        "    print(f\"📊 MLP       → Accuracy: {acc_mlp:.4f}, ROC-AUC: {auc_mlp:.4f}\")\n",
        "    print(f\"📊 XGBoost   → Accuracy: {acc_xgb:.4f}, ROC-AUC: {auc_xgb:.4f}\")\n",
        "    print(f\"🤝 Ensemble  → Accuracy: {acc_ens:.4f}, ROC-AUC: {auc_ens:.4f}\")\n",
        "\n",
        "    outer_accuracies.append(acc_ens)\n",
        "    outer_aucs.append(auc_ens)\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# ✅ Report Results\n",
        "# ==============================\n",
        "acc_mean = np.mean(outer_accuracies)\n",
        "acc_se = np.std(outer_accuracies, ddof=1) / np.sqrt(len(outer_accuracies))\n",
        "\n",
        "auc_mean = np.mean(outer_aucs)\n",
        "auc_se = np.std(outer_aucs, ddof=1) / np.sqrt(len(outer_aucs))\n",
        "\n",
        "print(\"\\n🧠 Final Evaluation Summary:\")\n",
        "print(f\"Accuracy: {acc_mean:.4f} ± {acc_se:.4f} (SE)\")\n",
        "print(f\"ROC-AUC:  {auc_mean:.4f} ± {auc_se:.4f} (SE)\")\n",
        "\n",
        "# Show per-fold results\n",
        "results_df = pd.DataFrame({\n",
        "    \"Fold\": list(range(1, 6)),\n",
        "    \"Accuracy\": outer_accuracies,\n",
        "    \"ROC-AUC\": outer_aucs\n",
        "})\n",
        "display(results_df)\n"
      ],
      "metadata": {
        "id": "foLuSpj1oZ1P",
        "outputId": "dac48af0-d05a-4927-c27f-dea6dc911051",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "🚀 Fold 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ Accuracy: 0.9854 | ROC-AUC: 0.9971\n",
            "\n",
            "🚀 Fold 2/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ Accuracy: 0.9864 | ROC-AUC: 0.9982\n",
            "\n",
            "🚀 Fold 3/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ Accuracy: 0.9867 | ROC-AUC: 0.9986\n",
            "\n",
            "🚀 Fold 4/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ Accuracy: 0.9873 | ROC-AUC: 0.9982\n",
            "\n",
            "🚀 Fold 5/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✔️ Accuracy: 0.9851 | ROC-AUC: 0.9984\n",
            "\n",
            "🧠 Final Evaluation Summary:\n",
            "Accuracy: 0.9862 ± 0.0004 (SE)\n",
            "ROC-AUC:  0.9981 ± 0.0003 (SE)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   Fold  Accuracy   ROC-AUC\n",
              "0     1  0.985422  0.997072\n",
              "1     2  0.986352  0.998206\n",
              "2     3  0.986663  0.998590\n",
              "3     4  0.987283  0.998154\n",
              "4     5  0.985112  0.998356"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32163ae9-8158-40ca-b421-cf5c0fe201fd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fold</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>ROC-AUC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.985422</td>\n",
              "      <td>0.997072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0.986352</td>\n",
              "      <td>0.998206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0.986663</td>\n",
              "      <td>0.998590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0.987283</td>\n",
              "      <td>0.998154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0.985112</td>\n",
              "      <td>0.998356</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32163ae9-8158-40ca-b421-cf5c0fe201fd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32163ae9-8158-40ca-b421-cf5c0fe201fd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32163ae9-8158-40ca-b421-cf5c0fe201fd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-174b186b-da93-4489-b1b1-0b47c18400df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-174b186b-da93-4489-b1b1-0b47c18400df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-174b186b-da93-4489-b1b1-0b47c18400df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_bb3df1b2-756a-4059-acbe-64ab8324f8fc\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_bb3df1b2-756a-4059-acbe-64ab8324f8fc button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "results_df",
              "summary": "{\n  \"name\": \"results_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Fold\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          2,\n          5,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0008936017550178755,\n        \"min\": 0.9851116625310173,\n        \"max\": 0.9872828784119106,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.9863523573200993,\n          0.9851116625310173,\n          0.9866625310173698\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ROC-AUC\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005859000314941085,\n        \"min\": 0.9970722065895363,\n        \"max\": 0.9985895947884662,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.998206303222112,\n          0.9983563872691784,\n          0.9985895947884662\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================\n",
        "# ✅ Load test set\n",
        "# ==============================\n",
        "test_csv = \"/content/drive/MyDrive/AllergenAI-new/CNN/algpred2_test_esm2_1280dim_embeddings.csv\"\n",
        "df_test = pd.read_csv(test_csv)\n",
        "X_test_final = df_test[feature_cols].values\n",
        "y_test_final = df_test[\"label\"].values\n",
        "\n",
        "# ==============================\n",
        "# ✅ Train on full training data (no CV)\n",
        "# ==============================\n",
        "mlp_pipeline.fit(X, y)\n",
        "xgb_clf.fit(X, y)\n",
        "\n",
        "# ==============================\n",
        "# ✅ Predict on test set (manual soft voting)\n",
        "# ==============================\n",
        "# Scale using fitted scaler from pipeline\n",
        "X_test_scaled = mlp_pipeline.named_steps['scaler'].transform(X_test_final)\n",
        "y_proba_mlp = mlp_pipeline.named_steps['mlp'].predict_proba(X_test_scaled)[:, 1]\n",
        "y_proba_xgb = xgb_clf.predict_proba(X_test_final)[:, 1]\n",
        "\n",
        "# Soft voting\n",
        "y_proba_test = 0.5 * y_proba_mlp + 0.5 * y_proba_xgb\n",
        "y_pred_test = (y_proba_test >= 0.5).astype(int)\n",
        "\n",
        "# ==============================\n",
        "# ✅ Evaluation\n",
        "# ==============================\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "test_acc = accuracy_score(y_test_final, y_pred_test)\n",
        "test_auc = roc_auc_score(y_test_final, y_proba_test)\n",
        "\n",
        "print(\"\\n🧪 Final Evaluation on Test Set (Soft-Voting Ensemble):\")\n",
        "print(f\"Accuracy: {test_acc:.4f}\")\n",
        "print(f\"ROC-AUC:  {test_auc:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_final, y_pred_test, digits=4))\n"
      ],
      "metadata": {
        "id": "FLFClOICsgfF",
        "outputId": "5552e364-5784-43f2-db4c-2938f06ee082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🧪 Final Evaluation on Test Set (Soft-Voting Ensemble):\n",
            "Accuracy: 0.8744\n",
            "ROC-AUC:  0.9802\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8041    0.9901    0.8875      2015\n",
            "           1     0.9871    0.7588    0.8580      2015\n",
            "\n",
            "    accuracy                         0.8744      4030\n",
            "   macro avg     0.8956    0.8744    0.8727      4030\n",
            "weighted avg     0.8956    0.8744    0.8727      4030\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Install dependencies\n",
        "!pip install -q xgboost pandas scikit-learn matplotlib numpy\n",
        "\n",
        "# ==============================\n",
        "# ✅ Imports and Setup\n",
        "# ==============================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# ==============================\n",
        "# ✅ Mount Google Drive\n",
        "# ==============================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "drive_path = \"/content/drive/MyDrive/AllergenAI-new/XGBoost\"\n",
        "os.makedirs(drive_path, exist_ok=True)\n",
        "print(f\"All generated files will be saved to: {drive_path}\")\n",
        "\n",
        "# ==============================\n",
        "# ✅ Load ESM-2 Embedding Data\n",
        "# ==============================\n",
        "train_csv = \"/content/drive/MyDrive/AllergenAI-new/CNN/algpred2_train_esm2_1280dim_embeddings.csv\"\n",
        "test_csv = \"/content/drive/MyDrive/AllergenAI-new/CNN/algpred2_test_esm2_1280dim_embeddings.csv\"\n",
        "\n",
        "df_train = pd.read_csv(train_csv)\n",
        "df_test = pd.read_csv(test_csv)\n",
        "\n",
        "feature_cols = [f\"f{i}\" for i in range(1280)]\n",
        "X_train = df_train[feature_cols].values\n",
        "y_train = df_train[\"label\"].values\n",
        "X_test = df_test[feature_cols].values\n",
        "y_test = df_test[\"label\"].values\n",
        "\n",
        "print(f\"Train size: {X_train.shape}, Test size: {X_test.shape}\")\n",
        "\n",
        "# ==============================\n",
        "# ✅ Hyperparameter Tuning for XGBoost\n",
        "# ==============================\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [3, 4, 5, 6],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'min_child_weight': [1, 3, 5]\n",
        "}\n",
        "\n",
        "# Create a smaller subset for hyperparameter tuning\n",
        "X_tune, _, y_tune, _ = train_test_split(X_train, y_train, test_size=0.7, random_state=42, stratify=y_train)\n",
        "\n",
        "# Initialize XGBoost classifier\n",
        "xgb = XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgb,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=20,\n",
        "    scoring='roc_auc',\n",
        "    cv=3,\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV\n",
        "print(\"\\n🔍 Starting hyperparameter tuning for XGBoost...\")\n",
        "random_search.fit(X_tune, y_tune)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = random_search.best_params_\n",
        "print(\"\\n✅ Best hyperparameters found:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"- {param}: {value}\")\n",
        "\n",
        "# Create the best XGBoost model with tuned hyperparameters\n",
        "xgb_best = XGBClassifier(\n",
        "    objective='binary:logistic',\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42,\n",
        "    **best_params\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# ✅ Nested Cross-Validation (5-fold)\n",
        "# ==============================\n",
        "print(\"\\n🔄 Performing 5-fold cross-validation...\")\n",
        "\n",
        "outer_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "outer_accuracies = []\n",
        "outer_aucs = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(outer_cv.split(X_train, y_train), 1):\n",
        "    print(f\"\\n🚀 Fold {fold}/5\")\n",
        "\n",
        "    X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
        "    y_fold_train, y_fold_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    # Create and fit the pipeline\n",
        "    pipeline = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('xgboost', xgb_best)\n",
        "    ])\n",
        "\n",
        "    # Train the model\n",
        "    pipeline.fit(\n",
        "        X_fold_train,\n",
        "        y_fold_train,\n",
        "        xgboost__eval_set=[(X_fold_val, y_fold_val)],\n",
        "        xgboost__early_stopping_rounds=10,\n",
        "        xgboost__verbose=0\n",
        "    )\n",
        "\n",
        "    # Get predictions\n",
        "    y_proba = pipeline.predict_proba(X_fold_val)[:, 1]\n",
        "    y_pred = (y_proba >= 0.5).astype(int)\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_fold_val, y_pred)\n",
        "    auc = roc_auc_score(y_fold_val, y_proba)\n",
        "\n",
        "    print(f\"📊 XGBoost → Accuracy: {acc:.4f}, ROC-AUC: {auc:.4f}\")\n",
        "\n",
        "    outer_accuracies.append(acc)\n",
        "    outer_aucs.append(auc)\n",
        "\n",
        "# ==============================\n",
        "# ✅ Report Cross-Validation Results\n",
        "# ==============================\n",
        "acc_mean = np.mean(outer_accuracies)\n",
        "acc_std = np.std(outer_accuracies, ddof=1)\n",
        "acc_se = acc_std / np.sqrt(len(outer_accuracies))\n",
        "\n",
        "auc_mean = np.mean(outer_aucs)\n",
        "auc_std = np.std(outer_aucs, ddof=1)\n",
        "auc_se = auc_std / np.sqrt(len(outer_aucs))\n",
        "\n",
        "print(\"\\n🧠 Cross-Validation Summary:\")\n",
        "print(f\"Accuracy: {acc_mean:.4f} ± {acc_se:.4f} (SE)\")\n",
        "print(f\"ROC-AUC:  {auc_mean:.4f} ± {auc_se:.4f} (SE)\")\n",
        "\n",
        "# Show per-fold results\n",
        "results_df = pd.DataFrame({\n",
        "    \"Fold\": list(range(1, 6)),\n",
        "    \"Accuracy\": outer_accuracies,\n",
        "    \"ROC-AUC\": outer_aucs\n",
        "})\n",
        "print(results_df)\n",
        "\n",
        "# ==============================\n",
        "# ✅ Y-Scrambling Control\n",
        "# ==============================\n",
        "import random\n",
        "\n",
        "print(\"\\n🔀 Performing Y-Scrambling control test...\")\n",
        "\n",
        "# Copy and shuffle labels\n",
        "y_scrambled = y_train.copy()\n",
        "random.seed(42)\n",
        "np.random.shuffle(y_scrambled)\n",
        "\n",
        "scrambled_aucs = []\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "for train_idx, val_idx in cv.split(X_train, y_scrambled):\n",
        "    X_fold_train, X_fold_val = X_train[train_idx], X_train[val_idx]\n",
        "    y_fold_train, y_fold_val = y_scrambled[train_idx], y_scrambled[val_idx]\n",
        "\n",
        "    # Simpler model for scrambling test\n",
        "    xgb_scramble = XGBClassifier(\n",
        "        n_estimators=100,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=3,\n",
        "        objective='binary:logistic',\n",
        "        use_label_encoder=False,\n",
        "        eval_metric='logloss',\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    xgb_scramble.fit(X_fold_train, y_fold_train)\n",
        "    y_proba_scrambled = xgb_scramble.predict_proba(X_fold_val)[:, 1]\n",
        "    auc = roc_auc_score(y_fold_val, y_proba_scrambled)\n",
        "    scrambled_aucs.append(auc)\n",
        "\n",
        "print(f\"Y-Scrambled AUC: {np.mean(scrambled_aucs):.4f} ± {np.std(scrambled_aucs):.4f}\")\n",
        "\n",
        "# ==============================\n",
        "# ✅ Train on full training data and evaluate on test set\n",
        "# ==============================\n",
        "print(\"\\n🧪 Training final model on full training data...\")\n",
        "\n",
        "# Create and fit the final pipeline\n",
        "final_pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('xgboost', xgb_best)\n",
        "])\n",
        "\n",
        "# Get validation data for early stopping\n",
        "X_train_fit, X_val, y_train_fit, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
        ")\n",
        "\n",
        "final_pipeline.fit(\n",
        "    X_train_fit,\n",
        "    y_train_fit,\n",
        "    xgboost__eval_set=[(X_val, y_val)],\n",
        "    xgboost__early_stopping_rounds=10,\n",
        "    xgboost__verbose=0\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# ✅ Predict on test set\n",
        "# ==============================\n",
        "y_test_proba = final_pipeline.predict_proba(X_test)[:, 1]\n",
        "y_test_pred = (y_test_proba >= 0.5).astype(int)\n",
        "\n",
        "# ==============================\n",
        "# ✅ Final Evaluation\n",
        "# ==============================\n",
        "test_acc = accuracy_score(y_test, y_test_pred)\n",
        "test_auc = roc_auc_score(y_test, y_test_proba)\n",
        "test_report = classification_report(y_test, y_test_pred, digits=4)\n",
        "\n",
        "print(\"\\n🏁 Final Evaluation on Test Set:\")\n",
        "print(f\"Accuracy: {test_acc:.4f}\")\n",
        "print(f\"ROC-AUC:  {test_auc:.4f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(test_report)\n",
        "\n",
        "# ==============================\n",
        "# ✅ Feature Importance Analysis\n",
        "# ==============================\n",
        "# Get feature importances\n",
        "feature_importances = final_pipeline.named_steps['xgboost'].feature_importances_\n",
        "\n",
        "# Create DataFrame with feature importances\n",
        "importance_df = pd.DataFrame({\n",
        "    'Feature': [f'f{i}' for i in range(1280)],\n",
        "    'Importance': feature_importances\n",
        "})\n",
        "\n",
        "# Sort by importance\n",
        "importance_df = importance_df.sort_values('Importance', ascending=False)\n",
        "\n",
        "# Plot top 20 features\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_features = importance_df.head(20)\n",
        "plt.barh(np.arange(len(top_features)), top_features['Importance'], align='center')\n",
        "plt.yticks(np.arange(len(top_features)), top_features['Feature'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Top 20 Important Features')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Save the plot\n",
        "importance_plot_path = os.path.join(drive_path, \"xgboost_feature_importance.png\")\n",
        "plt.savefig(importance_plot_path)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✅ Feature importance plot saved to: {importance_plot_path}\")\n",
        "\n",
        "# ==============================\n",
        "# ✅ Save the model and results\n",
        "# ==============================\n",
        "import pickle\n",
        "\n",
        "# Save the trained pipeline\n",
        "model_path = os.path.join(drive_path, \"allergen_xgboost_model.pkl\")\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(final_pipeline, f)\n",
        "\n",
        "# Save the results\n",
        "results = {\n",
        "    'cv_accuracy': acc_mean,\n",
        "    'cv_accuracy_se': acc_se,\n",
        "    'cv_auc': auc_mean,\n",
        "    'cv_auc_se': auc_se,\n",
        "    'test_accuracy': test_acc,\n",
        "    'test_auc': test_auc,\n",
        "    'best_params': best_params,\n",
        "    'y_scrambled_auc': np.mean(scrambled_aucs)\n",
        "}\n",
        "\n",
        "results_path = os.path.join(drive_path, \"allergen_xgboost_results.pkl\")\n",
        "with open(results_path, 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "\n",
        "# Save predictions on test set\n",
        "test_predictions = pd.DataFrame({\n",
        "    'id': df_test['id'],\n",
        "    'true_label': y_test,\n",
        "    'predicted_label': y_test_pred,\n",
        "    'probability': y_test_proba\n",
        "})\n",
        "\n",
        "predictions_path = os.path.join(drive_path, \"allergen_xgboost_test_predictions.csv\")\n",
        "test_predictions.to_csv(predictions_path, index=False)\n",
        "\n",
        "print(f\"\\n✅ Model saved to: {model_path}\")\n",
        "print(f\"✅ Results saved to: {results_path}\")\n",
        "print(f\"✅ Test predictions saved to: {predictions_path}\")\n",
        "\n",
        "# ==============================\n",
        "# ✅ Performance Visualization\n",
        "# ==============================\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "\n",
        "# ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_test_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Save ROC curve\n",
        "roc_path = os.path.join(drive_path, \"allergen_xgboost_roc_curve.png\")\n",
        "plt.savefig(roc_path)\n",
        "plt.show()\n",
        "\n",
        "# Precision-Recall Curve\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_test_proba)\n",
        "pr_auc = auc(recall, precision)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.plot(recall, precision, color='blue', lw=2, label=f'PR curve (area = {pr_auc:.4f})')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend(loc=\"lower left\")\n",
        "\n",
        "# Save PR curve\n",
        "pr_path = os.path.join(drive_path, \"allergen_xgboost_pr_curve.png\")\n",
        "plt.savefig(pr_path)\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n✅ ROC curve saved to: {roc_path}\")\n",
        "print(f\"✅ Precision-Recall curve saved to: {pr_path}\")\n",
        "print(\"\\n🎉 XGBoost analysis completed successfully!\")"
      ],
      "metadata": {
        "id": "MqZXT7-v0fYr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837d6d6a-f7ad-4fa3-a90c-f31ed00bcd35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "All generated files will be saved to: /content/drive/MyDrive/AllergenAI-new/XGBoost\n",
            "Train size: (16120, 1280), Test size: (4030, 1280)\n",
            "\n",
            "🔍 Starting hyperparameter tuning for XGBoost...\n",
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FJgju7xnsMge"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}