Ridge Classifier model chosen
algpred2_resplit dataset chosen
âœ… Loaded: Train=(16120, 320), Test=(4030, 320)

ðŸ“‰ DummyClassifier (Stratified) on Training Set (CV):

ðŸ“Š Dummy ROC-AUC: 0.4999 Â± 0.0028

ðŸš€ 5-Fold Cross-Validation (RidgeClassifier) on Training Set...

ðŸ“‚ Fold 1 AUC: 0.9259
              precision    recall  f1-score   support

           0     0.9288    0.9225    0.9256      1612
           1     0.9230    0.9293    0.9261      1612

    accuracy                         0.9259      3224
   macro avg     0.9259    0.9259    0.9259      3224
weighted avg     0.9259    0.9259    0.9259      3224

------
ðŸ“‚ Fold 2 AUC: 0.9293
              precision    recall  f1-score   support

           0     0.9369    0.9206    0.9287      1612
           1     0.9220    0.9380    0.9299      1612

    accuracy                         0.9293      3224
   macro avg     0.9294    0.9293    0.9293      3224
weighted avg     0.9294    0.9293    0.9293      3224

------
ðŸ“‚ Fold 3 AUC: 0.9262
              precision    recall  f1-score   support

           0     0.9409    0.9094    0.9249      1612
           1     0.9124    0.9429    0.9274      1612

    accuracy                         0.9262      3224
   macro avg     0.9267    0.9262    0.9262      3224
weighted avg     0.9267    0.9262    0.9262      3224

------
ðŸ“‚ Fold 4 AUC: 0.9296
              precision    recall  f1-score   support

           0     0.9304    0.9287    0.9295      1612
           1     0.9288    0.9305    0.9297      1612

    accuracy                         0.9296      3224
   macro avg     0.9296    0.9296    0.9296      3224
weighted avg     0.9296    0.9296    0.9296      3224

------
ðŸ“‚ Fold 5 AUC: 0.9249
              precision    recall  f1-score   support

           0     0.9265    0.9231    0.9248      1612
           1     0.9234    0.9268    0.9251      1612

    accuracy                         0.9249      3224
   macro avg     0.9249    0.9249    0.9249      3224
weighted avg     0.9249    0.9249    0.9249      3224

------

âœ… Mean CV ROC-AUC: 0.9272 Â± 0.0021 (SE = 0.0009)

ðŸ”’ Final Evaluation on Hold-Out Test Set...

              precision    recall  f1-score   support

           0     0.9349    0.9117    0.9231      2015
           1     0.9138    0.9365    0.9250      2015

    accuracy                         0.9241      4030
   macro avg     0.9243    0.9241    0.9241      4030
weighted avg     0.9243    0.9241    0.9241      4030

ðŸŽ¯ Final Test ROC-AUC: 0.9241

ðŸ§ª Y-Scrambling (sanity check) on Training Set...

ðŸ”€ Y-Scrambled ROC-AUC: 0.4988 Â± 0.0100
ðŸ‘‰ This should be near 0.5 if your real model learned something.
