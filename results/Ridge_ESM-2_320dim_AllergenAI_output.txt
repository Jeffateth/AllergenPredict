Ridge Classifier model chosen
AllergenAI dataset chosen
âœ… Loaded: Train=(15208, 320), Test=(3803, 320)

ðŸ“‰ DummyClassifier (Stratified) on Training Set (CV):

ðŸ“Š Dummy ROC-AUC: 0.4942 Â± 0.0060

ðŸš€ 5-Fold Cross-Validation (RidgeClassifier) on Training Set...

ðŸ“‚ Fold 1 AUC: 0.8724
              precision    recall  f1-score   support

           0     0.8723    0.8700    0.8712      1508
           1     0.8726    0.8748    0.8737      1534

    accuracy                         0.8725      3042
   macro avg     0.8725    0.8724    0.8724      3042
weighted avg     0.8725    0.8725    0.8725      3042

------
ðŸ“‚ Fold 2 AUC: 0.8653
              precision    recall  f1-score   support

           0     0.8593    0.8707    0.8650      1508
           1     0.8712    0.8598    0.8655      1534

    accuracy                         0.8652      3042
   macro avg     0.8652    0.8653    0.8652      3042
weighted avg     0.8653    0.8652    0.8652      3042

------
ðŸ“‚ Fold 3 AUC: 0.8738
              precision    recall  f1-score   support

           0     0.8732    0.8720    0.8726      1508
           1     0.8743    0.8755    0.8749      1534

    accuracy                         0.8738      3042
   macro avg     0.8738    0.8738    0.8738      3042
weighted avg     0.8738    0.8738    0.8738      3042

------
ðŸ“‚ Fold 4 AUC: 0.8649
              precision    recall  f1-score   support

           0     0.8582    0.8713    0.8647      1507
           1     0.8716    0.8585    0.8650      1534

    accuracy                         0.8648      3041
   macro avg     0.8649    0.8649    0.8648      3041
weighted avg     0.8649    0.8648    0.8648      3041

------
ðŸ“‚ Fold 5 AUC: 0.8753
              precision    recall  f1-score   support

           0     0.8785    0.8686    0.8735      1507
           1     0.8723    0.8820    0.8771      1534

    accuracy                         0.8754      3041
   macro avg     0.8754    0.8753    0.8753      3041
weighted avg     0.8754    0.8754    0.8754      3041

------

âœ… Mean CV ROC-AUC: 0.8703 Â± 0.0049 (SE = 0.0022)

ðŸ”’ Final Evaluation on Hold-Out Test Set...

              precision    recall  f1-score   support

           0     0.8715    0.8706    0.8710      1885
           1     0.8729    0.8738    0.8734      1918

    accuracy                         0.8722      3803
   macro avg     0.8722    0.8722    0.8722      3803
weighted avg     0.8722    0.8722    0.8722      3803

ðŸŽ¯ Final Test ROC-AUC: 0.8722

ðŸ§ª Y-Scrambling (sanity check) on Training Set...

ðŸ”€ Y-Scrambled ROC-AUC: 0.5009 Â± 0.0020
ðŸ‘‰ This should be near 0.5 if your real model learned something.
