FFNN model chosen
algpred2 dataset chosen
âœ… Loaded: Train=(16120, 320), Test=(4030, 320)

ðŸ“‰ DummyClassifier (Stratified) on Training Set (CV):

ðŸ“Š Dummy ROC-AUC: 0.4991 Â± 0.0000

ðŸš€ 5-Fold Cross-Validation (NN) on Training Set...

ðŸ“‚ Fold 1 AUC: 0.9911
              precision    recall  f1-score   support

         0.0     0.9727    0.9708    0.9717      1612
         1.0     0.9709    0.9727    0.9718      1612

    accuracy                         0.9718      3224
   macro avg     0.9718    0.9718    0.9718      3224
weighted avg     0.9718    0.9718    0.9718      3224

------
ðŸ“‚ Fold 2 AUC: 0.9929
              precision    recall  f1-score   support

         0.0     0.9656    0.9764    0.9710      1612
         1.0     0.9762    0.9653    0.9707      1612

    accuracy                         0.9708      3224
   macro avg     0.9709    0.9708    0.9708      3224
weighted avg     0.9709    0.9708    0.9708      3224

------
ðŸ“‚ Fold 3 AUC: 0.9942
              precision    recall  f1-score   support

         0.0     0.9724    0.9622    0.9673      1612
         1.0     0.9626    0.9727    0.9676      1612

    accuracy                         0.9674      3224
   macro avg     0.9675    0.9674    0.9674      3224
weighted avg     0.9675    0.9674    0.9674      3224

------
ðŸ“‚ Fold 4 AUC: 0.9946
              precision    recall  f1-score   support

         0.0     0.9791    0.9591    0.9690      1612
         1.0     0.9599    0.9795    0.9696      1612

    accuracy                         0.9693      3224
   macro avg     0.9695    0.9693    0.9693      3224
weighted avg     0.9695    0.9693    0.9693      3224

------
ðŸ“‚ Fold 5 AUC: 0.9945
              precision    recall  f1-score   support

         0.0     0.9749    0.9646    0.9698      1612
         1.0     0.9650    0.9752    0.9701      1612

    accuracy                         0.9699      3224
   macro avg     0.9700    0.9699    0.9699      3224
weighted avg     0.9700    0.9699    0.9699      3224

------

âœ… Mean CV ROC-AUC: 0.9935 Â± 0.0013

ðŸ”’ Final Evaluation on Hold-Out Test Set...

              precision    recall  f1-score   support

         0.0     0.7175    0.9831    0.8296      2015
         1.0     0.9732    0.6129    0.7521      2015

    accuracy                         0.7980      4030
   macro avg     0.8454    0.7980    0.7908      4030
weighted avg     0.8454    0.7980    0.7908      4030

ðŸŽ¯ Final Test ROC-AUC: 0.9254
